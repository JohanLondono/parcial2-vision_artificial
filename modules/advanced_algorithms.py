#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
M√≥dulo de Algoritmos Avanzados para An√°lisis de Tr√°fico Vehicular
=================================================================

Implementaci√≥n de algoritmos avanzados para identificaci√≥n de objetos 
en im√°genes de tr√°fico vehicular:

- FREAK (Fast Retina Keypoint): Descriptor binario inspirado en la retina humana
- AKAZE (Accelerated KAZE): Versi√≥n acelerada del detector KAZE
- GrabCut: Segmentaci√≥n interactiva de objetos
- LoG (Laplaciano de Gauss): Detecci√≥n de bordes avanzada
- Optical Flow: An√°lisis de movimiento entre frames
"""

import os
import csv
import json
import cv2
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
from skimage import feature, segmentation, filters, morphology
from skimage.filters import gaussian, laplace
from skimage.measure import label, regionprops
import seaborn as sns

class AdvancedAnalyzer:
    """Analizador de algoritmos avanzados para tr√°fico vehicular."""
    
    def __init__(self, output_dir="./resultados"):
        """
        Inicializar el analizador avanzado.
        
        Args:
            output_dir (str): Directorio de salida para resultados
        """
        self.output_dir = output_dir
        self.results_dir = os.path.join(output_dir, "advanced_analysis")
        os.makedirs(self.results_dir, exist_ok=True)
        self.current_results = []
        
        # Configuraciones por defecto
        self.config = {
            'akaze': {
                'threshold': 0.003,
                'nOctaves': 4,
                'nOctaveLayers': 4,
                'diffusivity': cv2.KAZE_DIFF_PM_G2,
                'descriptor_type': cv2.AKAZE_DESCRIPTOR_MLDB,
                'descriptor_size': 0,
                'descriptor_channels': 3
            },
            'log': {
                'sigma_values': [1, 2, 3, 4, 5],
                'threshold_factor': 0.1
            },
            'grabcut': {
                'iterations': 5,
                'margin': 10
            },
            'optical_flow': {
                'pyr_scale': 0.5,
                'levels': 3,
                'winsize': 15,
                'iterations': 3,
                'poly_n': 5,
                'poly_sigma': 1.2,
                'flags': 0
            }
        }
    
    def extraer_caracteristicas_freak(self, imagen, visualizar=True, mostrar_descriptores=True, guardar_resultados=False, nombre_imagen="imagen_freak"):
        """
        Extrae caracter√≠sticas FREAK (Fast Retina Keypoint).
        
        Args:
            imagen (np.ndarray): Imagen de entrada
            visualizar (bool): Si generar visualizaci√≥n
            mostrar_descriptores (bool): Si mostrar descriptores en consola
            guardar_resultados (bool): Si guardar resultados en archivos
            nombre_imagen (str): Nombre base para archivos guardados
            
        Returns:
            dict: Caracter√≠sticas FREAK extra√≠das
        """
        print("üîç Extrayendo caracter√≠sticas FREAK...")
        
        # Convertir a escala de grises
        if len(imagen.shape) == 3:
            imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
        else:
            imagen_gris = imagen.copy()
        
        try:
            # Crear detector STAR para puntos clave
            star = cv2.xfeatures2d.StarDetector_create()
            keypoints = star.detect(imagen_gris, None)
            
            # Crear descriptor FREAK
            freak = cv2.xfeatures2d.FREAK_create()
            keypoints, descriptors = freak.compute(imagen_gris, keypoints)
            
            freak_available = True
        except (AttributeError, cv2.error):
            # Fallback usando ORB para puntos clave y an√°lisis similar
            print("‚ö†Ô∏è  FREAK no disponible, usando an√°lisis alternativo...")
            orb = cv2.ORB_create(nfeatures=500)
            keypoints, descriptors = orb.detectAndCompute(imagen_gris, None)
            freak_available = False
        
        # An√°lisis de puntos clave
        num_keypoints = len(keypoints)
        
        if num_keypoints > 0 and descriptors is not None:
            # Estad√≠sticas de localizaci√≥n
            kp_x = [kp.pt[0] for kp in keypoints]
            kp_y = [kp.pt[1] for kp in keypoints]
            kp_size = [kp.size for kp in keypoints]
            kp_response = [kp.response for kp in keypoints]
            
            # An√°lisis de descriptores FREAK (binarios, 512 bits)
            bit_counts = np.unpackbits(descriptors, axis=1) if descriptors.dtype == np.uint8 else descriptors
            
            # Estad√≠sticas b√°sicas
            freak_stats = {
                'freak_num_keypoints': num_keypoints,
                'freak_kp_mean_x': np.mean(kp_x),
                'freak_kp_std_x': np.std(kp_x),
                'freak_kp_mean_y': np.mean(kp_y),
                'freak_kp_std_y': np.std(kp_y),
                'freak_kp_mean_size': np.mean(kp_size),
                'freak_kp_std_size': np.std(kp_size),
                'freak_kp_mean_response': np.mean(kp_response),
                'freak_kp_density': num_keypoints / (imagen_gris.shape[0] * imagen_gris.shape[1])
            }
            
            # An√°lisis espec√≠fico de FREAK (inspirado en retina)
            if descriptors.dtype == np.uint8:  # Descriptores binarios
                # An√°lisis de patrones binarios
                freak_stats.update({
                    'freak_bit_ratio': np.mean(bit_counts),
                    'freak_bit_entropy': self._calculate_entropy(bit_counts.flatten()),
                    'freak_descriptor_diversity': self._calculate_binary_diversity(descriptors),
                    'freak_pattern_complexity': self._calculate_pattern_complexity(descriptors)
                })
            else:  # Fallback con descriptores continuos
                freak_stats.update({
                    'freak_descriptor_mean': np.mean(descriptors),
                    'freak_descriptor_std': np.std(descriptors),
                    'freak_descriptor_energy': np.sum(descriptors ** 2),
                    'freak_descriptor_sparsity': np.sum(np.abs(descriptors) < 0.01) / descriptors.size
                })
            
            # An√°lisis espacial tipo retina (c√≠rculos conc√©ntricos)
            retina_stats = self._analizar_patron_retina(kp_x, kp_y, imagen_gris.shape)
            freak_stats.update(retina_stats)
            
        else:
            freak_stats = self._get_empty_freak_stats()
        
        freak_stats['freak_algorithm_available'] = freak_available
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            descriptor_name = 'FREAK' if freak_available else 'ORB (Fallback)'
            print(f"\nüîë AN√ÅLISIS DE CARACTER√çSTICAS {descriptor_name}")
            print("=" * 60)
            print(f"üìê Dimensiones de la imagen: {imagen_gris.shape}")
            print(f"üéØ N√∫mero de puntos clave detectados: {num_keypoints}")
            
            print(f"\nüìä Estad√≠sticas:")
            print(f"‚Ä¢ Algoritmo usado: {descriptor_name}")
            print(f"‚Ä¢ Puntos clave encontrados: {len(keypoints)}")
            if descriptors is not None:
                print(f"‚Ä¢ Dimensi√≥n del descriptor: {descriptors.shape[1] if len(descriptors.shape) > 1 else 'N/A'}")
                print(f"‚Ä¢ Tipo de descriptor: {'Binario' if descriptors.dtype == np.uint8 else 'Flotante'}")
                
            if num_keypoints > 0:
                print(f"‚Ä¢ Ubicaci√≥n promedio: ({np.mean(kp_x):.1f}, {np.mean(kp_y):.1f})")
                print(f"‚Ä¢ Tama√±o promedio: {np.mean(kp_size):.2f} ¬± {np.std(kp_size):.2f}")
                print(f"‚Ä¢ Respuesta promedio: {np.mean(kp_response):.6f}")
                print(f"‚Ä¢ Densidad de puntos: {freak_stats['freak_kp_density']:.6f}")
                
                # Mostrar an√°lisis espec√≠fico de FREAK
                if freak_available and descriptors is not None and descriptors.dtype == np.uint8:
                    print(f"‚Ä¢ Ratio de bits activos: {freak_stats.get('freak_bit_ratio', 0):.4f}")
                    print(f"‚Ä¢ Complejidad de patr√≥n: {freak_stats.get('freak_pattern_complexity', 0):.4f}")
                    print(f"‚Ä¢ Densidad centro retina: {freak_stats.get('retina_center_density', 0):.4f}")
                    print(f"‚Ä¢ Densidad periferia retina: {freak_stats.get('retina_periphery_density', 0):.4f}")
            
            print("=" * 60)
        
        resultados = {
            **freak_stats,
            'keypoints': keypoints,
            'descriptors': descriptors,
            'gray_image': imagen_gris,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_freak(resultados, nombre_imagen)
        
        if visualizar:
            # Establecer flag para guardar visualizaci√≥n si se est√°n guardando resultados
            if guardar_resultados:
                self._save_visualization = True
            self._visualizar_freak(resultados)
            if hasattr(self, '_save_visualization'):
                delattr(self, '_save_visualization')
        
        return resultados
    
    def extraer_caracteristicas_akaze(self, imagen, visualizar=True, mostrar_descriptores=True, guardar_resultados=False, nombre_imagen="imagen_akaze"):
        """
        Extrae caracter√≠sticas AKAZE (Accelerated KAZE).
        
        Args:
            imagen (np.ndarray): Imagen de entrada
            visualizar (bool): Si generar visualizaci√≥n
            mostrar_descriptores (bool): Si mostrar descriptores en consola
            guardar_resultados (bool): Si guardar resultados en archivos
            nombre_imagen (str): Nombre base para archivos guardados
            
        Returns:
            dict: Caracter√≠sticas AKAZE extra√≠das
        """
        print("üîç Extrayendo caracter√≠sticas AKAZE...")
        
        # Convertir a escala de grises
        if len(imagen.shape) == 3:
            imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
        else:
            imagen_gris = imagen.copy()
        
        # Crear detector AKAZE
        akaze = cv2.AKAZE_create(
            descriptor_type=self.config['akaze']['descriptor_type'],
            descriptor_size=self.config['akaze']['descriptor_size'],
            descriptor_channels=self.config['akaze']['descriptor_channels'],
            threshold=self.config['akaze']['threshold'],
            nOctaves=self.config['akaze']['nOctaves'],
            nOctaveLayers=self.config['akaze']['nOctaveLayers'],
            diffusivity=self.config['akaze']['diffusivity']
        )
        
        # Detectar puntos clave y calcular descriptores
        keypoints, descriptors = akaze.detectAndCompute(imagen_gris, None)
        
        # An√°lisis de puntos clave
        num_keypoints = len(keypoints)
        
        if num_keypoints > 0:
            # Estad√≠sticas de localizaci√≥n
            kp_x = [kp.pt[0] for kp in keypoints]
            kp_y = [kp.pt[1] for kp in keypoints]
            kp_size = [kp.size for kp in keypoints]
            kp_angle = [kp.angle for kp in keypoints]
            kp_response = [kp.response for kp in keypoints]
            kp_octave = [kp.octave for kp in keypoints]
            
            # Estad√≠sticas b√°sicas
            akaze_stats = {
                'akaze_num_keypoints': num_keypoints,
                'akaze_kp_mean_x': np.mean(kp_x),
                'akaze_kp_std_x': np.std(kp_x),
                'akaze_kp_mean_y': np.mean(kp_y),
                'akaze_kp_std_y': np.std(kp_y),
                'akaze_kp_mean_size': np.mean(kp_size),
                'akaze_kp_std_size': np.std(kp_size),
                'akaze_kp_mean_response': np.mean(kp_response),
                'akaze_kp_std_response': np.std(kp_response),
                'akaze_kp_density': num_keypoints / (imagen_gris.shape[0] * imagen_gris.shape[1])
            }
            
            # An√°lisis de escalas
            octave_counts = np.bincount([oct & 0xFF for oct in kp_octave])
            akaze_stats.update({
                'akaze_num_scales': len(octave_counts),
                'akaze_scale_entropy': self._calculate_entropy(octave_counts),
                'akaze_dominant_scale': np.argmax(octave_counts) if len(octave_counts) > 0 else 0
            })
            
            # An√°lisis de orientaciones
            valid_angles = [angle for angle in kp_angle if angle >= 0]
            if valid_angles:
                angle_hist, _ = np.histogram(valid_angles, bins=36, range=(0, 360))
                akaze_stats.update({
                    'akaze_mean_angle': np.mean(valid_angles),
                    'akaze_std_angle': np.std(valid_angles),
                    'akaze_angle_entropy': self._calculate_entropy(angle_hist)
                })
            
            # An√°lisis de descriptores AKAZE
            if descriptors is not None:
                descriptor_stats = self._analizar_descriptores_akaze(descriptors)
                akaze_stats.update(descriptor_stats)
            
            # An√°lisis de estabilidad multi-escala
            stability_stats = self._analizar_estabilidad_multiescala(keypoints, imagen_gris)
            akaze_stats.update(stability_stats)
            
        else:
            akaze_stats = self._get_empty_akaze_stats()
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            print(f"\nüîë AN√ÅLISIS DE CARACTER√çSTICAS AKAZE")
            print("=" * 60)
            print(f"üìê Dimensiones de la imagen: {imagen_gris.shape}")
            
            if num_keypoints > 0:
                print(f"\nüìä An√°lisis AKAZE:")
                print(f"‚Ä¢ Puntos clave detectados: {len(keypoints)}")
                print(f"‚Ä¢ Tama√±o promedio: {np.mean(kp_size):.2f} ¬± {np.std(kp_size):.2f}")
                print(f"‚Ä¢ Respuesta promedio: {np.mean(kp_response):.4f}")
                print(f"‚Ä¢ Rango de orientaciones: {np.min(kp_angle):.1f}¬∞ a {np.max(kp_angle):.1f}¬∞")
                if descriptors is not None:
                    print(f"‚Ä¢ Dimensi√≥n del descriptor: {descriptors.shape[1]}")
                    print(f"‚Ä¢ Tipo de descriptor: {descriptors.dtype}")
                print(f"‚Ä¢ Densidad de puntos: {akaze_stats['akaze_kp_density']:.6f}")
                print(f"‚Ä¢ N√∫mero de escalas: {akaze_stats['akaze_num_scales']}")
                print(f"‚Ä¢ Estabilidad multi-escala: {akaze_stats.get('akaze_scale_stability', 0):.4f}")
            else:
                print("‚ö†Ô∏è No se detectaron puntos clave con AKAZE")
            
            print("=" * 60)
        
        resultados = {
            **akaze_stats,
            'keypoints': keypoints,
            'descriptors': descriptors,
            'gray_image': imagen_gris,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_akaze(resultados, nombre_imagen)
        
        if visualizar:
            # Establecer flag para guardar visualizaci√≥n si se est√°n guardando resultados
            if guardar_resultados:
                self._save_visualization = True
            self._visualizar_akaze(resultados)
            if hasattr(self, '_save_visualization'):
                delattr(self, '_save_visualization')
        
        return resultados
    
    def analizar_grabcut_segmentation(self, imagen, visualizar=True, mostrar_descriptores=True, guardar_resultados=False, nombre_imagen="imagen_grabcut"):
        """
        Realiza segmentaci√≥n usando GrabCut.
        
        Args:
            imagen (np.ndarray): Imagen de entrada
            visualizar (bool): Si generar visualizaci√≥n
            mostrar_descriptores (bool): Si mostrar estad√≠sticas en consola
            guardar_resultados (bool): Si guardar resultados en archivos
            nombre_imagen (str): Nombre base para archivos guardados
            
        Returns:
            dict: Resultados de segmentaci√≥n GrabCut
        """
        print("üîç Analizando segmentaci√≥n GrabCut...")
        
        if len(imagen.shape) != 3:
            print("‚ö†Ô∏è  GrabCut requiere imagen en color, convirtiendo...")
            imagen = cv2.cvtColor(imagen, cv2.COLOR_GRAY2BGR)
        
        h, w = imagen.shape[:2]
        margin = self.config['grabcut']['margin']
        
        # Crear rect√°ngulo inicial (regi√≥n central)
        rect = (margin, margin, w - 2*margin, h - 2*margin)
        
        # Inicializar m√°scaras
        mask = np.zeros((h, w), np.uint8)
        bgd_model = np.zeros((1, 65), np.float64)
        fgd_model = np.zeros((1, 65), np.float64)
        
        # Aplicar GrabCut
        cv2.grabCut(imagen, mask, rect, bgd_model, fgd_model, 
                   self.config['grabcut']['iterations'], cv2.GC_INIT_WITH_RECT)
        
        # Crear m√°scara binaria
        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
        
        # An√°lisis de la segmentaci√≥n
        foreground_pixels = np.sum(mask2)
        background_pixels = np.sum(1 - mask2)
        total_pixels = h * w
        
        # An√°lisis de componentes conectados
        labeled_mask = label(mask2)
        regions = regionprops(labeled_mask)
        
        # Estad√≠sticas de regiones
        if regions:
            areas = [region.area for region in regions]
            centroids = [region.centroid for region in regions]
            
            grabcut_stats = {
                'grabcut_foreground_ratio': foreground_pixels / total_pixels,
                'grabcut_background_ratio': background_pixels / total_pixels,
                'grabcut_num_regions': len(regions),
                'grabcut_largest_region_area': max(areas) if areas else 0,
                'grabcut_mean_region_area': np.mean(areas) if areas else 0,
                'grabcut_std_region_area': np.std(areas) if areas else 0,
                'grabcut_region_compactness': np.mean([region.extent for region in regions]) if regions else 0,
                'grabcut_region_solidity': np.mean([region.solidity for region in regions]) if regions else 0
            }
            
            # An√°lisis de distribuci√≥n espacial de regiones
            if centroids:
                centroid_x = [c[1] for c in centroids]  # columna
                centroid_y = [c[0] for c in centroids]  # fila
                
                grabcut_stats.update({
                    'grabcut_centroid_mean_x': np.mean(centroid_x),
                    'grabcut_centroid_std_x': np.std(centroid_x),
                    'grabcut_centroid_mean_y': np.mean(centroid_y),
                    'grabcut_centroid_std_y': np.std(centroid_y)
                })
        else:
            grabcut_stats = self._get_empty_grabcut_stats()
        
        # An√°lisis de calidad de segmentaci√≥n
        edge_coherence = self._calcular_coherencia_bordes(imagen, mask2)
        grabcut_stats['grabcut_edge_coherence'] = edge_coherence
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            print(f"\nüîë AN√ÅLISIS DE SEGMENTACI√ìN GRABCUT")
            print("=" * 60)
            print(f"üìê Dimensiones de la imagen: {imagen.shape}")
            
            print(f"\nüìä Estad√≠sticas GrabCut:")
            print(f"‚Ä¢ P√≠xeles totales: {total_pixels:,}")
            print(f"‚Ä¢ P√≠xeles de primer plano: {foreground_pixels:,} ({100*foreground_pixels/total_pixels:.1f}%)")
            print(f"‚Ä¢ P√≠xeles de fondo: {background_pixels:,} ({100*background_pixels/total_pixels:.1f}%)")
            print(f"‚Ä¢ Iteraciones: {self.config['grabcut']['iterations']}")
            
            if regions:
                print(f"‚Ä¢ N√∫mero de regiones: {len(regions)}")
                print(f"‚Ä¢ √Årea de regi√≥n m√°s grande: {max(areas):,} p√≠xeles")
                print(f"‚Ä¢ √Årea promedio de regiones: {np.mean(areas):.1f} p√≠xeles")
                print(f"‚Ä¢ Compacidad promedio: {grabcut_stats['grabcut_region_compactness']:.4f}")
                print(f"‚Ä¢ Solidez promedio: {grabcut_stats['grabcut_region_solidity']:.4f}")
            
            print(f"‚Ä¢ Coherencia de bordes: {edge_coherence:.4f}")
            print("=" * 60)
        
        resultados = {
            **grabcut_stats,
            'original_image': imagen,
            'segmentation_mask': mask2,
            'labeled_regions': labeled_mask,
            'regions': regions,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_grabcut(resultados, nombre_imagen)
        
        if visualizar:
            # Establecer flag para guardar visualizaci√≥n si se est√°n guardando resultados
            if guardar_resultados:
                self._save_visualization = True
            self._visualizar_grabcut(resultados)
            if hasattr(self, '_save_visualization'):
                delattr(self, '_save_visualization')
        
        return resultados
    
    def analizar_log_detector(self, imagen, visualizar=True, mostrar_descriptores=True, guardar_resultados=False, nombre_imagen="imagen_log"):
        """
        Analiza usando Laplaciano de Gauss (LoG).
        
        Args:
            imagen (np.ndarray): Imagen de entrada
            visualizar (bool): Si generar visualizaci√≥n
            mostrar_descriptores (bool): Si mostrar estad√≠sticas en consola
            guardar_resultados (bool): Si guardar resultados en archivos
            nombre_imagen (str): Nombre base para archivos guardados
            
        Returns:
            dict: Resultados del an√°lisis LoG
        """
        print("üîç Analizando con Laplaciano de Gauss (LoG)...")
        
        # Convertir a escala de grises
        if len(imagen.shape) == 3:
            imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
        else:
            imagen_gris = imagen.copy()
        
        # Normalizar imagen
        imagen_norm = imagen_gris.astype(np.float64) / 255.0
        
        # Aplicar LoG con diferentes sigmas
        log_responses = []
        log_stats = {}
        
        for i, sigma in enumerate(self.config['log']['sigma_values']):
            # Aplicar filtro Gaussiano seguido de Laplaciano
            gaussian_img = gaussian(imagen_norm, sigma=sigma)
            log_response = laplace(gaussian_img)
            log_responses.append(log_response)
            
            # Estad√≠sticas por escala
            log_stats[f'log_sigma_{sigma}_mean'] = np.mean(np.abs(log_response))
            log_stats[f'log_sigma_{sigma}_std'] = np.std(log_response)
            log_stats[f'log_sigma_{sigma}_energy'] = np.sum(log_response ** 2)
            log_stats[f'log_sigma_{sigma}_entropy'] = self._calculate_entropy(log_response.flatten())
        
        # An√°lisis multi-escala
        log_stack = np.stack(log_responses, axis=2)
        
        # Detecci√≥n de blobs usando m√°ximos locales
        threshold = self.config['log']['threshold_factor'] * np.max(np.abs(log_stack))
        
        # Encontrar m√°ximos locales en el espacio de escalas
        local_maxima = []
        for i in range(1, len(self.config['log']['sigma_values']) - 1):
            current_scale = np.abs(log_responses[i])
            prev_scale = np.abs(log_responses[i-1])
            next_scale = np.abs(log_responses[i+1])
            
            # M√°ximos locales en escala y espacio
            mask = (current_scale > prev_scale) & (current_scale > next_scale) & (current_scale > threshold)
            coords = np.where(mask)
            
            for y, x in zip(coords[0], coords[1]):
                local_maxima.append({
                    'x': x, 'y': y, 'sigma': self.config['log']['sigma_values'][i],
                    'response': current_scale[y, x]
                })
        
        # Estad√≠sticas de detecci√≥n
        num_blobs = len(local_maxima)
        
        if local_maxima:
            blob_x = [blob['x'] for blob in local_maxima]
            blob_y = [blob['y'] for blob in local_maxima]
            blob_sigma = [blob['sigma'] for blob in local_maxima]
            blob_response = [blob['response'] for blob in local_maxima]
            
            detection_stats = {
                'log_num_blobs': num_blobs,
                'log_blob_density': num_blobs / (imagen_gris.shape[0] * imagen_gris.shape[1]),
                'log_mean_x': np.mean(blob_x),
                'log_std_x': np.std(blob_x),
                'log_mean_y': np.mean(blob_y),
                'log_std_y': np.std(blob_y),
                'log_mean_sigma': np.mean(blob_sigma),
                'log_std_sigma': np.std(blob_sigma),
                'log_mean_response': np.mean(blob_response),
                'log_std_response': np.std(blob_response)
            }
        else:
            detection_stats = {
                'log_num_blobs': 0, 'log_blob_density': 0,
                'log_mean_x': 0, 'log_std_x': 0,
                'log_mean_y': 0, 'log_std_y': 0,
                'log_mean_sigma': 0, 'log_std_sigma': 0,
                'log_mean_response': 0, 'log_std_response': 0
            }
        
        # An√°lisis de estructura multi-escala
        scale_consistency = self._analizar_consistencia_escalas(log_responses)
        
        all_stats = {**log_stats, **detection_stats, **scale_consistency}
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            print(f"\nüîë AN√ÅLISIS LAPLACIANO DE GAUSS (LoG)")
            print("=" * 60)
            print(f"üìê Dimensiones de la imagen: {imagen_gris.shape}")
            
            print(f"\nüìä Estad√≠sticas LoG:")
            print(f"‚Ä¢ Valores de sigma analizados: {self.config['log']['sigma_values']}")
            print(f"‚Ä¢ N√∫mero de blobs detectados: {num_blobs}")
            print(f"‚Ä¢ Densidad de blobs: {detection_stats['log_blob_density']:.6f}")
            
            if num_blobs > 0:
                print(f"‚Ä¢ Ubicaci√≥n promedio: ({detection_stats['log_mean_x']:.1f}, {detection_stats['log_mean_y']:.1f})")
                print(f"‚Ä¢ Sigma promedio: {detection_stats['log_mean_sigma']:.2f} ¬± {detection_stats['log_std_sigma']:.2f}")
                print(f"‚Ä¢ Respuesta promedio: {detection_stats['log_mean_response']:.6f}")
                print(f"‚Ä¢ Consistencia entre escalas: {scale_consistency.get('log_scale_consistency', 0):.4f}")
            
            # Estad√≠sticas por escala
            print(f"\nüìà An√°lisis multi-escala:")
            for i, sigma in enumerate(self.config['log']['sigma_values']):
                if i < len(log_stats):
                    response_mean = log_stats.get(f'log_sigma_{sigma}_mean', 0)
                    response_std = log_stats.get(f'log_sigma_{sigma}_std', 0)
                    print(f"‚Ä¢ Sigma {sigma}: Œº={response_mean:.4f}, œÉ={response_std:.4f}")
            
            print("=" * 60)
        
        resultados = {
            **all_stats,
            'log_responses': log_responses,
            'local_maxima': local_maxima,
            'gray_image': imagen_gris,
            'normalized_image': imagen_norm,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_log(resultados, nombre_imagen)
        
        if visualizar:
            self._visualizar_log(resultados)
        
        return resultados
    
    def analizar_optical_flow(self, imagen1, imagen2=None, visualizar=True, mostrar_descriptores=True, guardar_resultados=False, nombre_imagen="imagen_optical_flow"):
        """
        Analiza flujo √≥ptico entre dos im√°genes.
        
        Args:
            imagen1 (np.ndarray): Primera imagen o imagen √∫nica
            imagen2 (np.ndarray o str, optional): Segunda imagen (array) o ruta a la segunda imagen
            visualizar (bool): Si generar visualizaci√≥n
            mostrar_descriptores (bool): Si mostrar estad√≠sticas en consola
            guardar_resultados (bool): Si guardar resultados en archivos
            nombre_imagen (str): Nombre base para archivos guardados
            
        Returns:
            dict: Resultados del an√°lisis de flujo √≥ptico
        """
        print("üîç Analizando flujo √≥ptico...")
        
        # Si imagen2 es una ruta (string), cargarla
        if isinstance(imagen2, str):
            try:
                imagen2_ruta = imagen2  # Guardar la ruta original
                imagen2_cargada = cv2.imread(imagen2)
                if imagen2_cargada is None:
                    print(f"‚ùå Error: No se pudo cargar la imagen: {imagen2}")
                    return None
                imagen2 = imagen2_cargada
                print(f"‚úÖ Segunda imagen cargada: {os.path.basename(imagen2_ruta)}")
            except Exception as e:
                print(f"‚ùå Error cargando segunda imagen: {e}")
                return None
        
        # Si solo se proporciona una imagen, crear una versi√≥n desplazada
        if imagen2 is None:
            print("‚ö†Ô∏è  Solo una imagen proporcionada, creando desplazamiento artificial...")
            # Crear desplazamiento artificial para demostrar
            if len(imagen1.shape) == 3:
                imagen1_gris = cv2.cvtColor(imagen1, cv2.COLOR_BGR2GRAY)
            else:
                imagen1_gris = imagen1.copy()
            
            # Desplazamiento y rotaci√≥n ligera
            h, w = imagen1_gris.shape
            M = cv2.getRotationMatrix2D((w/2, h/2), 1, 1.02)  # Rotaci√≥n de 1¬∞ y escala 1.02
            M[0, 2] += 2  # Desplazamiento en X
            M[1, 2] += 1  # Desplazamiento en Y
            
            imagen2_gris = cv2.warpAffine(imagen1_gris, M, (w, h))
        else:
            # Convertir ambas im√°genes a escala de grises
            if len(imagen1.shape) == 3:
                imagen1_gris = cv2.cvtColor(imagen1, cv2.COLOR_BGR2GRAY)
            else:
                imagen1_gris = imagen1.copy()
            
            if len(imagen2.shape) == 3:
                imagen2_gris = cv2.cvtColor(imagen2, cv2.COLOR_BGR2GRAY)
            else:
                imagen2_gris = imagen2.copy()
        
        # Calcular flujo √≥ptico denso (Farneback)
        flow = cv2.calcOpticalFlowFarneback(imagen1_gris, imagen2_gris,
                                           None,
                                           pyr_scale=self.config['optical_flow']['pyr_scale'],
                                           levels=self.config['optical_flow']['levels'],
                                           winsize=self.config['optical_flow']['winsize'],
                                           iterations=self.config['optical_flow']['iterations'],
                                           poly_n=self.config['optical_flow']['poly_n'],
                                           poly_sigma=self.config['optical_flow']['poly_sigma'],
                                           flags=self.config['optical_flow']['flags'])
        
        # Calcular magnitud y √°ngulo del flujo
        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])
        
        # Estad√≠sticas del flujo √≥ptico
        flow_stats = {
            'optical_flow_mean_magnitude': np.mean(magnitude),
            'optical_flow_std_magnitude': np.std(magnitude),
            'optical_flow_max_magnitude': np.max(magnitude),
            'optical_flow_mean_angle': np.mean(angle),
            'optical_flow_std_angle': np.std(angle)
        }
        
        # An√°lisis direccional del movimiento
        angle_deg = np.degrees(angle)
        angle_hist, _ = np.histogram(angle_deg.flatten(), bins=36, range=(0, 360))
        flow_stats['optical_flow_direction_entropy'] = self._calculate_entropy(angle_hist)
        flow_stats['optical_flow_dominant_direction'] = np.argmax(angle_hist) * 10  # grados
        
        # An√°lisis de regiones de movimiento
        movement_threshold = np.mean(magnitude) + np.std(magnitude)
        moving_pixels = magnitude > movement_threshold
        flow_stats['optical_flow_movement_ratio'] = np.sum(moving_pixels) / moving_pixels.size
        
        # An√°lisis de coherencia espacial
        coherence = self._calcular_coherencia_flujo(flow)
        flow_stats['optical_flow_spatial_coherence'] = coherence
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            print(f"\nüîë AN√ÅLISIS DE FLUJO √ìPTICO")
            print("=" * 60)
            print(f"üìê Dimensiones de la imagen: {imagen1_gris.shape}")
            
            print(f"\nüìä Estad√≠sticas Optical Flow:")
            print(f"‚Ä¢ Algoritmo: Farneback (Flujo √≥ptico denso)")
            print(f"‚Ä¢ Magnitud promedio: {flow_stats['optical_flow_mean_magnitude']:.4f}")
            print(f"‚Ä¢ Magnitud m√°xima: {flow_stats['optical_flow_max_magnitude']:.4f}")
            print(f"‚Ä¢ Desviaci√≥n est√°ndar magnitud: {flow_stats['optical_flow_std_magnitude']:.4f}")
            print(f"‚Ä¢ √Ångulo promedio: {np.degrees(flow_stats['optical_flow_mean_angle']):.1f}¬∞")
            print(f"‚Ä¢ Direcci√≥n dominante: {flow_stats['optical_flow_dominant_direction']:.0f}¬∞")
            print(f"‚Ä¢ Entrop√≠a direccional: {flow_stats['optical_flow_direction_entropy']:.4f}")
            print(f"‚Ä¢ Ratio de p√≠xeles en movimiento: {flow_stats['optical_flow_movement_ratio']:.4f}")
            print(f"‚Ä¢ Coherencia espacial: {flow_stats['optical_flow_spatial_coherence']:.4f}")
            
            # Informaci√≥n sobre el m√©todo
            print(f"\n‚öôÔ∏è Configuraci√≥n:")
            print(f"‚Ä¢ Escala piramidal: {self.config['optical_flow']['pyr_scale']}")
            print(f"‚Ä¢ Niveles: {self.config['optical_flow']['levels']}")
            print(f"‚Ä¢ Tama√±o ventana: {self.config['optical_flow']['winsize']}")
            print(f"‚Ä¢ Iteraciones: {self.config['optical_flow']['iterations']}")
            
            print("=" * 60)
        
        resultados = {
            **flow_stats,
            'flow_field': flow,
            'magnitude': magnitude,
            'angle': angle,
            'image1': imagen1_gris,
            'image2': imagen2_gris if imagen2 is not None else imagen2_gris,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_optical_flow(resultados, nombre_imagen)
        
        if visualizar:
            self._visualizar_optical_flow(resultados)
        
        return resultados
    
    def analizar_optical_flow_profesora(self, imagen1, imagen2=None, visualizar=True, mostrar_descriptores=True, 
                                      guardar_resultados=False, nombre_imagen="imagen_optical_flow_prof"):
        """
        Analiza flujo √≥ptico usando exactamente el m√©todo de la profesora.
        Implementaci√≥n directa del c√≥digo proporcionado por la profesora.
        
        Args:
            imagen1 (np.ndarray): Primera imagen o imagen √∫nica
            imagen2 (np.ndarray o str, optional): Segunda imagen (array) o ruta a la segunda imagen
            visualizar (bool): Si generar visualizaci√≥n
            mostrar_descriptores (bool): Si mostrar estad√≠sticas en consola
            guardar_resultados (bool): Si guardar resultados en archivos
            nombre_imagen (str): Nombre base para archivos guardados
            
        Returns:
            dict: Resultados del an√°lisis de flujo √≥ptico (m√©todo profesora)
        """
        print("üîç Analizando flujo √≥ptico (M√©todo de la Profesora)...")
        
        # Si imagen2 es una ruta (string), cargarla
        if isinstance(imagen2, str):
            try:
                frame2 = cv2.imread(imagen2, cv2.IMREAD_GRAYSCALE)
                if frame2 is None:
                    print(f"‚ùå Error: No se pudo cargar la imagen: {imagen2}")
                    frame2 = None
                else:
                    print(f"‚úÖ Segunda imagen cargada: {os.path.basename(imagen2)}")
            except Exception as e:
                print(f"‚ùå Error cargando segunda imagen: {e}")
                frame2 = None
        elif imagen2 is not None:
            # Convertir a escala de grises si es necesario
            if len(imagen2.shape) == 3:
                frame2 = cv2.cvtColor(imagen2, cv2.COLOR_BGR2GRAY)
            else:
                frame2 = imagen2.copy()
        else:
            # Como en el c√≥digo de la profesora: usar la misma imagen para frame2
            frame2 = None
        
        # Cargar dos im√°genes consecutivas de un video (como en c√≥digo de la profesora)
        if isinstance(imagen1, str):
            frame1 = cv2.imread(imagen1, cv2.IMREAD_GRAYSCALE)
        else:
            if len(imagen1.shape) == 3:
                frame1 = cv2.cvtColor(imagen1, cv2.COLOR_BGR2GRAY)
            else:
                frame1 = imagen1.copy()
        
        # Si no hay segunda imagen, usar la misma (como en el ejemplo de la profesora)
        if frame2 is None:
            frame2 = frame1.copy()
        
        # Verificar si las im√°genes se cargaron correctamente
        if frame1 is None or frame2 is None:
            print("‚ö†Ô∏è Problema con las im√°genes, creando frames de ejemplo...")
            # Crear frames de ejemplo (c√≥digo exacto de la profesora)
            frame1 = np.zeros((300, 400), dtype=np.uint8)
            cv2.circle(frame1, (100, 150), 30, 255, -1)
            cv2.circle(frame1, (200, 100), 25, 255, -1)
            
            # Frame2 con ligero desplazamiento
            frame2 = np.zeros((300, 400), dtype=np.uint8)
            cv2.circle(frame2, (105, 150), 30, 255, -1)  # Desplazado 5 p√≠xeles
            cv2.circle(frame2, (205, 100), 25, 255, -1)  # Desplazado 5 p√≠xeles
        
        # Calcular el flujo √≥ptico usando el m√©todo de Farneback (c√≥digo exacto de la profesora)
        flow = cv2.calcOpticalFlowFarneback(frame1, frame2, None, 0.5, 3, 15, 3, 5, 1.2, 0)
        
        # Convertir el flujo √≥ptico a un formato visualizable (c√≥digo exacto de la profesora)
        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])
        hsv = np.zeros_like(frame1, dtype=np.float32)
        # Apilar im√°genes en escala de grises para tener 3 canales
        hsv = np.stack((hsv, hsv, hsv), axis=-1)
        hsv[..., 1] = 255
        hsv[..., 0] = ang * 180 / np.pi / 2
        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)
        flow_rgb = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
        
        # Estad√≠sticas b√°sicas
        mag_promedio = np.mean(mag)
        mag_maxima = np.max(mag)
        mag_std = np.std(mag)
        ang_promedio = np.mean(ang)
        
        # Estad√≠sticas del flujo √≥ptico (m√©todo profesora)
        flow_stats = {
            'optical_flow_mean_magnitude': mag_promedio,
            'optical_flow_max_magnitude': mag_maxima,
            'optical_flow_std_magnitude': mag_std,
            'optical_flow_mean_angle': ang_promedio,
            'optical_flow_method': 'profesora_farneback',
            'optical_flow_parameters': {
                'pyr_scale': 0.5,
                'levels': 3,
                'winsize': 15,
                'iterations': 3,
                'poly_n': 5,
                'poly_sigma': 1.2,
                'flags': 0
            }
        }
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            print(f"\nüîë AN√ÅLISIS DE FLUJO √ìPTICO (M√âTODO PROFESORA)")
            print("=" * 60)
            print(f"üìê Dimensiones de la imagen: {frame1.shape}")
            
            print(f"\nüìä Estad√≠sticas Optical Flow:")
            print(f"‚Ä¢ M√©todo: Farneback (Implementaci√≥n Profesora)")
            print(f"‚Ä¢ Magnitud promedio: {mag_promedio:.4f}")
            print(f"‚Ä¢ Magnitud m√°xima: {mag_maxima:.4f}")
            print(f"‚Ä¢ Desviaci√≥n est√°ndar magnitud: {mag_std:.4f}")
            print(f"‚Ä¢ √Ångulo promedio: {np.degrees(ang_promedio):.1f}¬∞")
            
            # Informaci√≥n sobre el m√©todo
            print(f"\n‚öôÔ∏è Par√°metros utilizados:")
            print(f"‚Ä¢ Escala piramidal: 0.5")
            print(f"‚Ä¢ Niveles: 3")
            print(f"‚Ä¢ Tama√±o ventana: 15")
            print(f"‚Ä¢ Iteraciones: 3")
            print(f"‚Ä¢ Polinomio N: 5")
            print(f"‚Ä¢ Polinomio Sigma: 1.2")
            
            print("=" * 60)
        
        resultados = {
            **flow_stats,
            'flow_field': flow,
            'magnitude': mag,
            'angle': ang,
            'flow_rgb': flow_rgb,
            'hsv_representation': hsv,
            'frame1': frame1,
            'frame2': frame2,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_optical_flow_profesora(resultados, nombre_imagen)
        
        if visualizar:
            self._visualizar_optical_flow_profesora(resultados)
        
        return resultados
    
    def analizar_secuencia_imagenes_carpeta(self, carpeta_path, patron_archivos="*.jpg", 
                                          visualizar=True, guardar_resultados=True,
                                          nombre_secuencia="secuencia_movimiento"):
        """
        Analiza una secuencia de im√°genes en una carpeta para detectar cambios de movimiento.
        √ötil para analizar series temporales de im√°genes y detectar patrones.
        
        Args:
            carpeta_path (str): Ruta a la carpeta con las im√°genes
            patron_archivos (str): Patr√≥n para filtrar archivos (ej: "*.jpg", "*.png")
            visualizar (bool): Si generar visualizaciones
            guardar_resultados (bool): Si guardar resultados
            nombre_secuencia (str): Nombre para los archivos de resultados
            
        Returns:
            dict: An√°lisis completo de la secuencia de im√°genes
        """
        print(f"üìÅ Analizando secuencia de im√°genes en carpeta: {carpeta_path}")
        
        import glob
        
        # Verificar que la carpeta existe
        if not os.path.exists(carpeta_path):
            print(f"‚ùå Error: La carpeta no existe: {carpeta_path}")
            return None
        
        # Buscar archivos de imagen
        patron_completo = os.path.join(carpeta_path, patron_archivos)
        archivos_imagen = sorted(glob.glob(patron_completo))
        
        if len(archivos_imagen) < 2:
            print(f"‚ùå Error: Se necesitan al menos 2 im√°genes. Encontradas: {len(archivos_imagen)}")
            return None
        
        print(f"üìä Encontradas {len(archivos_imagen)} im√°genes")
        print(f"üîç Analizando secuencia de movimientos...")
        
        # Variables para an√°lisis de secuencia
        secuencia_flujos = []
        estadisticas_secuencia = []
        cambios_movimiento = []
        magnitudes_globales = []
        
        # Cargar primera imagen
        try:
            imagen_anterior = cv2.imread(archivos_imagen[0], cv2.IMREAD_GRAYSCALE)
            if imagen_anterior is None:
                print(f"‚ùå Error cargando primera imagen: {archivos_imagen[0]}")
                return None
        except Exception as e:
            print(f"‚ùå Error: {e}")
            return None
        
        print("üîÑ Procesando secuencia...")
        
        for i in range(1, len(archivos_imagen)):
            try:
                # Cargar imagen actual
                imagen_actual = cv2.imread(archivos_imagen[i], cv2.IMREAD_GRAYSCALE)
                if imagen_actual is None:
                    print(f"‚ö†Ô∏è Saltando imagen corrupta: {archivos_imagen[i]}")
                    continue
                
                # Redimensionar si es necesario para que coincidan
                if imagen_actual.shape != imagen_anterior.shape:
                    imagen_actual = cv2.resize(imagen_actual, 
                                             (imagen_anterior.shape[1], imagen_anterior.shape[0]))
                
                # Calcular optical flow entre im√°genes consecutivas (m√©todo profesora)
                flow = cv2.calcOpticalFlowFarneback(imagen_anterior, imagen_actual, None, 
                                                  0.5, 3, 15, 3, 5, 1.2, 0)
                
                # Calcular magnitud y √°ngulo
                magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])
                
                # Estad√≠sticas de esta transici√≥n
                stats_transicion = {
                    'imagen_anterior': os.path.basename(archivos_imagen[i-1]),
                    'imagen_actual': os.path.basename(archivos_imagen[i]),
                    'indice': i,
                    'magnitude_mean': np.mean(magnitude),
                    'magnitude_max': np.max(magnitude),
                    'magnitude_std': np.std(magnitude),
                    'angle_mean': np.mean(angle),
                    'movement_intensity': np.sum(magnitude > np.mean(magnitude)),
                    'movement_area': np.sum(magnitude > (np.mean(magnitude) + np.std(magnitude)))
                }
                
                estadisticas_secuencia.append(stats_transicion)
                secuencia_flujos.append(flow)
                magnitudes_globales.append(np.mean(magnitude))
                
                # Detectar cambios significativos de movimiento
                if len(magnitudes_globales) > 1:
                    cambio_relativo = (magnitudes_globales[-1] - magnitudes_globales[-2]) / (magnitudes_globales[-2] + 1e-10)
                    
                    if abs(cambio_relativo) > 0.5:  # Cambio mayor al 50%
                        tipo_cambio = "incremento" if cambio_relativo > 0 else "reduccion"
                        cambios_movimiento.append({
                            'posicion': i,
                            'tipo': tipo_cambio,
                            'magnitude_anterior': magnitudes_globales[-2],
                            'magnitude_actual': magnitudes_globales[-1],
                            'cambio_relativo': cambio_relativo,
                            'imagen_anterior': archivos_imagen[i-1],
                            'imagen_actual': archivos_imagen[i]
                        })
                
                # Actualizar imagen anterior
                imagen_anterior = imagen_actual.copy()
                
                # Mostrar progreso
                if i % 5 == 0:
                    print(f"üìà Procesadas {i}/{len(archivos_imagen)-1} transiciones...")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Error procesando {archivos_imagen[i]}: {e}")
                continue
        
        # An√°lisis global de la secuencia
        if estadisticas_secuencia:
            analisis_global = self._analizar_secuencia_global(estadisticas_secuencia, cambios_movimiento)
        else:
            print("‚ùå No se pudieron procesar las im√°genes")
            return None
        
        # Resultados finales
        resultados = {
            'carpeta_path': carpeta_path,
            'archivos_procesados': archivos_imagen,
            'num_transiciones': len(estadisticas_secuencia),
            'estadisticas_secuencia': estadisticas_secuencia,
            'cambios_movimiento': cambios_movimiento,
            'magnitudes_globales': magnitudes_globales,
            'analisis_global': analisis_global,
            'secuencia_flujos': secuencia_flujos[:10] if len(secuencia_flujos) > 10 else secuencia_flujos,  # Limitar memoria
            'nombre_secuencia': nombre_secuencia
        }
        
        print(f"‚úÖ An√°lisis de secuencia completado: {len(estadisticas_secuencia)} transiciones procesadas")
        print(f"üîÑ Cambios de movimiento detectados: {len(cambios_movimiento)}")
        
        # Guardar resultados
        if guardar_resultados:
            self._guardar_resultados_secuencia(resultados, nombre_secuencia)
        
        # Visualizar resultados
        if visualizar:
            self._visualizar_secuencia_imagenes(resultados)
        
        return resultados
    
    def analizar_video_optical_flow(self, video_path, max_frames=None, skip_frames=1, extraer_caracteristicas=True, 
                                  guardar_resultados=True, nombre_video="video_analisis"):
        """
        Analiza secuencias de video usando optical flow para detectar patrones de movimiento.
        √ötil para entrenar modelos de visi√≥n artificial y detectar eventos en videos.
        
        Args:
            video_path (str): Ruta al archivo de video (.avi, .mp4, etc.)
            max_frames (int, optional): N√∫mero m√°ximo de frames a procesar
            skip_frames (int): Procesar cada N frames (para acelerar an√°lisis)
            extraer_caracteristicas (bool): Si extraer caracter√≠sticas temporales
            guardar_resultados (bool): Si guardar resultados de an√°lisis
            nombre_video (str): Nombre base para archivos guardados
            
        Returns:
            dict: An√°lisis temporal del video con optical flow
        """
        print(f"üé¨ Analizando video: {video_path}")
        
        # Verificar que el archivo existe
        if not os.path.exists(video_path):
            print(f"‚ùå Error: No se encontr√≥ el video: {video_path}")
            return None
        
        try:
            # Abrir video
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print(f"‚ùå Error: No se pudo abrir el video: {video_path}")
                return None
            
            # Propiedades del video
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = total_frames / fps if fps > 0 else 0
            
            print(f"üìä Propiedades del video:")
            print(f"‚Ä¢ Resoluci√≥n: {width}x{height}")
            print(f"‚Ä¢ FPS: {fps:.2f}")
            print(f"‚Ä¢ Total de frames: {total_frames}")
            print(f"‚Ä¢ Duraci√≥n: {duration:.2f} segundos")
            
            # Limitar frames si se especifica
            frames_to_process = min(max_frames, total_frames) if max_frames else total_frames
            print(f"‚Ä¢ Frames a procesar: {frames_to_process} (cada {skip_frames} frames)")
            
            # Leer primer frame
            ret, frame1 = cap.read()
            if not ret:
                print("‚ùå Error: No se pudo leer el primer frame")
                cap.release()
                return None
            
            # Convertir a escala de grises
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
            
            # Variables para an√°lisis temporal
            flow_sequences = []
            movement_patterns = []
            frame_statistics = []
            motion_history = []
            
            frame_count = 0
            processed_count = 0
            
            print("üîÑ Procesando frames...")
            
            while True:
                ret, frame2 = cap.read()
                if not ret or processed_count >= frames_to_process:
                    break
                
                frame_count += 1
                
                # Saltar frames si es necesario
                if frame_count % skip_frames != 0:
                    continue
                
                # Convertir a escala de grises
                gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
                
                # Calcular optical flow
                flow = cv2.calcOpticalFlowFarneback(
                    gray1, gray2, None,
                    pyr_scale=self.config['optical_flow']['pyr_scale'],
                    levels=self.config['optical_flow']['levels'],
                    winsize=self.config['optical_flow']['winsize'],
                    iterations=self.config['optical_flow']['iterations'],
                    poly_n=self.config['optical_flow']['poly_n'],
                    poly_sigma=self.config['optical_flow']['poly_sigma'],
                    flags=self.config['optical_flow']['flags']
                )
                
                # Calcular magnitud y √°ngulo
                magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])
                
                # Estad√≠sticas del frame actual
                frame_stats = {
                    'frame_number': frame_count,
                    'timestamp': frame_count / fps,
                    'mean_magnitude': np.mean(magnitude),
                    'max_magnitude': np.max(magnitude),
                    'std_magnitude': np.std(magnitude),
                    'motion_density': np.sum(magnitude > np.mean(magnitude)) / magnitude.size,
                    'dominant_direction': np.degrees(np.mean(angle)),
                    'movement_area': np.sum(magnitude > (np.mean(magnitude) + np.std(magnitude)))
                }
                
                frame_statistics.append(frame_stats)
                flow_sequences.append(flow)
                
                # Detectar patrones de movimiento
                if extraer_caracteristicas:
                    pattern = self._extraer_patron_movimiento(flow, magnitude, angle)
                    movement_patterns.append(pattern)
                
                # Actualizar historial de movimiento
                motion_intensity = np.mean(magnitude)
                motion_history.append(motion_intensity)
                
                # Actualizar frame anterior
                gray1 = gray2.copy()
                processed_count += 1
                
                # Mostrar progreso
                if processed_count % 10 == 0:
                    print(f"üìà Procesados {processed_count}/{frames_to_process} frames...")
            
            cap.release()
            
            # An√°lisis temporal completo
            video_analysis = self._analizar_secuencia_temporal(
                frame_statistics, movement_patterns, motion_history, fps
            )
            
            # Resultados finales
            resultados = {
                'video_path': video_path,
                'video_properties': {
                    'width': width, 'height': height, 'fps': fps,
                    'total_frames': total_frames, 'duration': duration,
                    'processed_frames': processed_count
                },
                'frame_statistics': frame_statistics,
                'movement_patterns': movement_patterns,
                'motion_history': motion_history,
                'temporal_analysis': video_analysis,
                'flow_sequences': flow_sequences[:10] if len(flow_sequences) > 10 else flow_sequences,  # Guardar solo los primeros 10 para memoria
                'nombre_video': nombre_video
            }
            
            print(f"‚úÖ An√°lisis de video completado: {processed_count} frames procesados")
            
            # Guardar resultados
            if guardar_resultados:
                self._guardar_resultados_video(resultados, nombre_video)
            
            # Generar visualizaci√≥n
            self._visualizar_analisis_video(resultados)
            
            return resultados
            
        except Exception as e:
            print(f"‚ùå Error durante el an√°lisis del video: {e}")
            return None
    
    def _extraer_patron_movimiento(self, flow, magnitude, angle):
        """Extrae patrones espec√≠ficos de movimiento del optical flow."""
        h, w = flow.shape[:2]
        
        # Dividir imagen en regiones para an√°lisis local
        regions = {
            'centro': magnitude[h//4:3*h//4, w//4:3*w//4],
            'esquina_superior_izq': magnitude[0:h//2, 0:w//2],
            'esquina_superior_der': magnitude[0:h//2, w//2:w],
            'esquina_inferior_izq': magnitude[h//2:h, 0:w//2],
            'esquina_inferior_der': magnitude[h//2:h, w//2:w]
        }
        
        # An√°lisis direccional
        angle_deg = np.degrees(angle)
        direcciones = {
            'arriba': np.sum((angle_deg >= 45) & (angle_deg < 135)),
            'abajo': np.sum((angle_deg >= 225) & (angle_deg < 315)),
            'izquierda': np.sum((angle_deg >= 135) & (angle_deg < 225)),
            'derecha': np.sum(((angle_deg >= 315) & (angle_deg <= 360)) | ((angle_deg >= 0) & (angle_deg < 45)))
        }
        
        # Detectar tipos de movimiento
        total_motion = np.sum(magnitude > np.mean(magnitude))
        movement_type = "estatico"
        
        if total_motion > 0.1 * magnitude.size:
            if direcciones['derecha'] > direcciones['izquierda'] * 1.5:
                movement_type = "movimiento_derecha"
            elif direcciones['izquierda'] > direcciones['derecha'] * 1.5:
                movement_type = "movimiento_izquierda"
            elif direcciones['arriba'] > direcciones['abajo'] * 1.5:
                movement_type = "movimiento_arriba"
            elif direcciones['abajo'] > direcciones['arriba'] * 1.5:
                movement_type = "movimiento_abajo"
            else:
                movement_type = "movimiento_multiple"
        
        return {
            'type': movement_type,
            'total_motion': total_motion,
            'region_activity': {region: np.mean(mag) for region, mag in regions.items()},
            'directional_distribution': direcciones,
            'motion_intensity': np.mean(magnitude),
            'motion_complexity': np.std(angle_deg)
        }
    
    def _analizar_secuencia_temporal(self, frame_stats, patterns, motion_history, fps):
        """Analiza la secuencia temporal completa del video."""
        if not frame_stats:
            return {}
        
        # An√°lisis de tendencias temporales
        magnitudes = [stat['mean_magnitude'] for stat in frame_stats]
        motion_densities = [stat['motion_density'] for stat in frame_stats]
        timestamps = [stat['timestamp'] for stat in frame_stats]
        
        # Detectar eventos significativos (picos de movimiento)
        threshold = np.mean(magnitudes) + 2 * np.std(magnitudes)
        eventos = []
        
        for i, (mag, timestamp) in enumerate(zip(magnitudes, timestamps)):
            if mag > threshold:
                eventos.append({
                    'frame': frame_stats[i]['frame_number'],
                    'timestamp': timestamp,
                    'magnitude': mag,
                    'type': 'high_motion_event'
                })
        
        # An√°lisis de periodicidad
        periodicidad = self._detectar_periodicidad(motion_history)
        
        # Clasificaci√≥n de actividad general
        actividad_promedio = np.mean(magnitudes)
        if actividad_promedio < 0.5:
            nivel_actividad = "baja"
        elif actividad_promedio < 2.0:
            nivel_actividad = "media"
        else:
            nivel_actividad = "alta"
        
        # An√°lisis de patrones de movimiento dominantes
        if patterns:
            tipos_movimiento = [p['type'] for p in patterns]
            tipo_dominante = max(set(tipos_movimiento), key=tipos_movimiento.count)
        else:
            tipo_dominante = "desconocido"
        
        return {
            'duracion_total': timestamps[-1] if timestamps else 0,
            'actividad_promedio': actividad_promedio,
            'nivel_actividad': nivel_actividad,
            'eventos_significativos': eventos,
            'num_eventos': len(eventos),
            'patron_dominante': tipo_dominante,
            'periodicidad': periodicidad,
            'variabilidad_temporal': np.std(magnitudes),
            'tendencia_movimiento': 'creciente' if magnitudes[-1] > magnitudes[0] else 'decreciente',
            'picos_actividad': len([m for m in magnitudes if m > threshold]),
            'frames_activos': len([d for d in motion_densities if d > 0.1]),
            'estabilidad': 'estable' if np.std(magnitudes) < np.mean(magnitudes) * 0.5 else 'variable'
        }
    
    def _detectar_periodicidad(self, motion_history, min_period=3):
        """Detecta patrones peri√≥dicos en el historial de movimiento."""
        if len(motion_history) < min_period * 2:
            return {'detected': False, 'period': 0, 'confidence': 0}
        
        # Usar autocorrelaci√≥n para detectar periodicidad
        motion_array = np.array(motion_history)
        motion_normalized = (motion_array - np.mean(motion_array)) / np.std(motion_array)
        
        # Calcular autocorrelaci√≥n
        max_lag = min(len(motion_history) // 3, 50)
        autocorr = []
        
        for lag in range(1, max_lag):
            if lag < len(motion_normalized):
                corr = np.corrcoef(motion_normalized[:-lag], motion_normalized[lag:])[0, 1]
                if not np.isnan(corr):
                    autocorr.append(corr)
                else:
                    autocorr.append(0)
        
        if autocorr:
            max_corr_idx = np.argmax(autocorr)
            max_corr = autocorr[max_corr_idx]
            
            if max_corr > 0.3:  # Umbral para periodicidad significativa
                return {
                    'detected': True,
                    'period': max_corr_idx + 1,
                    'confidence': max_corr,
                    'autocorrelation': autocorr[:20]  # Primeros 20 valores
                }
        
        return {'detected': False, 'period': 0, 'confidence': 0}
    
    def _visualizar_analisis_video(self, resultados):
        """Visualiza el an√°lisis temporal del video."""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        frame_stats = resultados['frame_statistics']
        if not frame_stats:
            print("‚ö†Ô∏è No hay estad√≠sticas de frames para visualizar")
            return
        
        timestamps = [stat['timestamp'] for stat in frame_stats]
        magnitudes = [stat['mean_magnitude'] for stat in frame_stats]
        motion_densities = [stat['motion_density'] for stat in frame_stats]
        movement_areas = [stat['movement_area'] for stat in frame_stats]
        
        # 1. Magnitud del movimiento a lo largo del tiempo
        axes[0].plot(timestamps, magnitudes, 'b-', linewidth=2)
        axes[0].set_title('Magnitud de Movimiento vs Tiempo')
        axes[0].set_xlabel('Tiempo (segundos)')
        axes[0].set_ylabel('Magnitud Promedio')
        axes[0].grid(True, alpha=0.3)
        
        # 2. Densidad de movimiento
        axes[1].plot(timestamps, motion_densities, 'g-', linewidth=2)
        axes[1].set_title('Densidad de Movimiento')
        axes[1].set_xlabel('Tiempo (segundos)')
        axes[1].set_ylabel('Densidad de P√≠xeles en Movimiento')
        axes[1].grid(True, alpha=0.3)
        
        # 3. √Årea de movimiento
        axes[2].fill_between(timestamps, movement_areas, alpha=0.6, color='orange')
        axes[2].set_title('√Årea de Movimiento Significativo')
        axes[2].set_xlabel('Tiempo (segundos)')
        axes[2].set_ylabel('P√≠xeles')
        axes[2].grid(True, alpha=0.3)
        
        # 4. Histograma de magnitudes
        axes[3].hist(magnitudes, bins=20, alpha=0.7, color='purple', edgecolor='black')
        axes[3].set_title('Distribuci√≥n de Magnitudes')
        axes[3].set_xlabel('Magnitud')
        axes[3].set_ylabel('Frecuencia')
        axes[3].grid(True, alpha=0.3)
        
        # 5. Eventos significativos
        eventos = resultados['temporal_analysis'].get('eventos_significativos', [])
        if eventos:
            event_times = [e['timestamp'] for e in eventos]
            event_mags = [e['magnitude'] for e in eventos]
            axes[4].scatter(event_times, event_mags, color='red', s=100, alpha=0.7)
            axes[4].plot(timestamps, magnitudes, 'b-', alpha=0.5)
            axes[4].set_title(f'Eventos Significativos ({len(eventos)})')
            axes[4].set_xlabel('Tiempo (segundos)')
            axes[4].set_ylabel('Magnitud')
        else:
            axes[4].text(0.5, 0.5, 'No se detectaron\neventos significativos', 
                        ha='center', va='center', transform=axes[4].transAxes, fontsize=12)
            axes[4].set_title('Eventos Significativos')
        axes[4].grid(True, alpha=0.3)
        
        # 6. An√°lisis de periodicidad
        periodicidad = resultados['temporal_analysis'].get('periodicidad', {})
        if periodicidad.get('detected', False):
            autocorr = periodicidad.get('autocorrelation', [])
            if autocorr:
                axes[5].plot(range(1, len(autocorr) + 1), autocorr, 'r-', linewidth=2)
                axes[5].axhline(y=0.3, color='g', linestyle='--', alpha=0.7, label='Umbral significativo')
                axes[5].set_title(f'Periodicidad Detectada (Per√≠odo: {periodicidad["period"]})')
                axes[5].set_xlabel('Lag (frames)')
                axes[5].set_ylabel('Autocorrelaci√≥n')
                axes[5].legend()
        else:
            axes[5].text(0.5, 0.5, 'No se detect√≥\nperiodicidad', 
                        ha='center', va='center', transform=axes[5].transAxes, fontsize=12)
            axes[5].set_title('An√°lisis de Periodicidad')
        axes[5].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"video_analysis_{resultados['nombre_video']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è An√°lisis de video guardado: {imagen_filename}")
        
        plt.show()
        
        # Mostrar resumen textual
        temporal_analysis = resultados['temporal_analysis']
        print(f"\nüìä RESUMEN DEL AN√ÅLISIS DE VIDEO")
        print("=" * 60)
        print(f"üé¨ Video: {os.path.basename(resultados['video_path'])}")
        print(f"‚è±Ô∏è Duraci√≥n: {temporal_analysis['duracion_total']:.2f} segundos")
        print(f"üìà Nivel de actividad: {temporal_analysis['nivel_actividad'].upper()}")
        print(f"üéØ Patr√≥n dominante: {temporal_analysis['patron_dominante']}")
        print(f"üîÑ Periodicidad: {'S√ç' if temporal_analysis['periodicidad']['detected'] else 'NO'}")
        if temporal_analysis['periodicidad']['detected']:
            print(f"   ‚Üí Per√≠odo: {temporal_analysis['periodicidad']['period']} frames")
            print(f"   ‚Üí Confianza: {temporal_analysis['periodicidad']['confidence']:.3f}")
        print(f"‚ö° Eventos significativos: {temporal_analysis['num_eventos']}")
        print(f"üìä Estabilidad: {temporal_analysis['estabilidad']}")
        print(f"üìà Tendencia: {temporal_analysis['tendencia_movimiento']}")
        print("=" * 60)

    def analisis_completo_avanzado(self, imagen_path, imagen2_path=None, nombre_imagen=None):
        """
        Realiza an√°lisis completo con algoritmos avanzados.
        
        Args:
            imagen_path (str): Ruta a la primera imagen
            imagen2_path (str, optional): Ruta a la segunda imagen para optical flow
            nombre_imagen (str): Nombre personalizado
            
        Returns:
            dict: Resultados combinados
        """
        try:
            # Cargar primera imagen
            imagen1 = cv2.imread(imagen_path)
            if imagen1 is None:
                raise ValueError(f"No se pudo cargar la imagen: {imagen_path}")
            
            # Cargar segunda imagen si se proporciona
            imagen2 = None
            if imagen2_path:
                imagen2 = cv2.imread(imagen2_path)
                if imagen2 is None:
                    print(f"‚ö†Ô∏è  No se pudo cargar la segunda imagen: {imagen2_path}")
            
            if nombre_imagen is None:
                nombre_imagen = os.path.basename(imagen_path)
            
            print(f"üîÑ An√°lisis avanzado para: {nombre_imagen}")
            
            # An√°lisis FREAK
            resultados_freak = self.extraer_caracteristicas_freak(imagen1, visualizar=False)
            
            # An√°lisis AKAZE
            resultados_akaze = self.extraer_caracteristicas_akaze(imagen1, visualizar=False)
            
            # An√°lisis GrabCut
            resultados_grabcut = self.analizar_grabcut_segmentation(imagen1, visualizar=False)
            
            # An√°lisis LoG
            resultados_log = self.analizar_log_detector(imagen1, visualizar=False)
            
            # An√°lisis Optical Flow
            resultados_flow = self.analizar_optical_flow(imagen1, imagen2, visualizar=False)
            
            # Combinar resultados
            resultado_completo = {
                'Imagen': nombre_imagen,
                'Ruta': imagen_path,
                'Ruta_Imagen2': imagen2_path if imagen2_path else 'N/A',
                'Dimensiones': imagen1.shape,
                'Fecha_Analisis': datetime.now().isoformat(),
                **{k: v for k, v in resultados_freak.items() 
                   if not isinstance(v, (list, np.ndarray))},
                **{k: v for k, v in resultados_akaze.items() 
                   if not isinstance(v, (list, np.ndarray))},
                **{k: v for k, v in resultados_grabcut.items() 
                   if not isinstance(v, (list, np.ndarray))},
                **{k: v for k, v in resultados_log.items() 
                   if not isinstance(v, (list, np.ndarray))},
                **{k: v for k, v in resultados_flow.items() 
                   if not isinstance(v, (list, np.ndarray))}
            }
            
            self.current_results.append(resultado_completo)
            
            print(f"‚úÖ An√°lisis avanzado completado para: {nombre_imagen}")
            return resultado_completo
            
        except Exception as e:
            print(f"‚ùå Error al procesar {imagen_path}: {str(e)}")
            return None
    
    def _analizar_secuencia_global(self, estadisticas_secuencia, cambios_movimiento):
        """Analiza globalmente una secuencia de im√°genes."""
        if not estadisticas_secuencia:
            return {}
        
        # Extraer magnitudes
        magnitudes = [stat['magnitude_mean'] for stat in estadisticas_secuencia]
        intensidades = [stat['movement_intensity'] for stat in estadisticas_secuencia]
        
        # An√°lisis de tendencias
        tendencia = "estable"
        if len(magnitudes) > 1:
            diferencia_total = magnitudes[-1] - magnitudes[0]
            if diferencia_total > 0.1:
                tendencia = "creciente"
            elif diferencia_total < -0.1:
                tendencia = "decreciente"
        
        # Detectar picos y valles
        picos = []
        valles = []
        threshold_pico = np.mean(magnitudes) + np.std(magnitudes)
        threshold_valle = np.mean(magnitudes) - np.std(magnitudes)
        
        for i, mag in enumerate(magnitudes):
            if mag > threshold_pico:
                picos.append(i)
            elif mag < threshold_valle:
                valles.append(i)
        
        # Estabilidad de la secuencia
        variabilidad = np.std(magnitudes) / (np.mean(magnitudes) + 1e-10)
        if variabilidad < 0.3:
            estabilidad = "muy_estable"
        elif variabilidad < 0.6:
            estabilidad = "estable"
        elif variabilidad < 1.0:
            estabilidad = "variable"
        else:
            estabilidad = "muy_variable"
        
        # An√°lisis de periodicidad simple
        periodicidad_detectada = False
        if len(magnitudes) > 6:
            # Buscar patrones simples
            autocorr = np.correlate(magnitudes, magnitudes, mode='full')
            autocorr = autocorr[autocorr.size // 2:]
            if len(autocorr) > 3 and np.max(autocorr[2:]) > 0.7 * autocorr[0]:
                periodicidad_detectada = True
        
        return {
            'tendencia_general': tendencia,
            'estabilidad': estabilidad,
            'variabilidad': variabilidad,
            'magnitude_promedio': np.mean(magnitudes),
            'magnitude_max': np.max(magnitudes),
            'magnitude_min': np.min(magnitudes),
            'num_picos': len(picos),
            'num_valles': len(valles),
            'posiciones_picos': picos,
            'posiciones_valles': valles,
            'num_cambios_significativos': len(cambios_movimiento),
            'periodicidad_detectada': periodicidad_detectada,
            'intensidad_promedio': np.mean(intensidades),
            'transiciones_procesadas': len(estadisticas_secuencia)
        }
    
    # M√©todos auxiliares
    def _calculate_entropy(self, data):
        """Calcula la entrop√≠a de los datos."""
        if isinstance(data, np.ndarray):
            data = data.flatten()
        
        hist, _ = np.histogram(data, bins=50, density=True)
        hist = hist[hist > 0]
        
        if len(hist) == 0:
            return 0
        
        return -np.sum(hist * np.log2(hist))
    
    def _calculate_binary_diversity(self, descriptors):
        """Calcula diversidad entre descriptores binarios."""
        if descriptors is None or len(descriptors) < 2:
            return 0
        
        # Calcular distancias de Hamming
        hamming_distances = []
        for i in range(min(len(descriptors), 50)):
            for j in range(i+1, min(len(descriptors), 50)):
                hamming_dist = np.sum(descriptors[i] != descriptors[j])
                hamming_distances.append(hamming_dist)
        
        return np.mean(hamming_distances) if hamming_distances else 0
    
    def _calculate_pattern_complexity(self, descriptors):
        """Calcula complejidad de patrones en descriptores binarios."""
        if descriptors is None or len(descriptors) == 0:
            return 0
        
        # Analizar transiciones de bits (cambios 0->1 o 1->0)
        transitions = []
        for descriptor in descriptors[:50]:  # Limitar para eficiencia
            bit_array = np.unpackbits(descriptor) if descriptor.dtype == np.uint8 else descriptor
            transition_count = np.sum(bit_array[:-1] != bit_array[1:])
            transitions.append(transition_count)
        
        return np.mean(transitions) if transitions else 0
    
    def _analizar_patron_retina(self, kp_x, kp_y, image_shape):
        """Analiza distribuci√≥n de puntos clave en patr√≥n tipo retina."""
        if not kp_x or not kp_y:
            return {
                'retina_center_density': 0,
                'retina_periphery_density': 0,
                'retina_radial_gradient': 0
            }
        
        h, w = image_shape[:2]
        center_x, center_y = w/2, h/2
        max_radius = min(w, h) / 2
        
        # Dividir en anillos conc√©ntricos (como la retina)
        distances = [np.sqrt((x - center_x)**2 + (y - center_y)**2) 
                    for x, y in zip(kp_x, kp_y)]
        
        # Contar puntos en diferentes anillos
        center_points = sum(1 for d in distances if d < max_radius * 0.3)
        mid_points = sum(1 for d in distances if max_radius * 0.3 <= d < max_radius * 0.7)
        periphery_points = sum(1 for d in distances if d >= max_radius * 0.7)
        
        total_points = len(kp_x)
        
        return {
            'retina_center_density': center_points / total_points if total_points > 0 else 0,
            'retina_mid_density': mid_points / total_points if total_points > 0 else 0,
            'retina_periphery_density': periphery_points / total_points if total_points > 0 else 0,
            'retina_radial_gradient': (center_points - periphery_points) / total_points if total_points > 0 else 0
        }
    
    def _analizar_descriptores_akaze(self, descriptors):
        """Analiza descriptores AKAZE."""
        if descriptors is None or len(descriptors) == 0:
            return {
                'akaze_descriptor_length': 0,
                'akaze_descriptor_mean': 0,
                'akaze_descriptor_std': 0,
                'akaze_descriptor_sparsity': 0,
                'akaze_descriptor_energy': 0
            }
        
        # Los descriptores AKAZE pueden ser binarios o de punto flotante
        if descriptors.dtype == np.uint8:
            # Descriptores binarios
            bit_counts = np.unpackbits(descriptors, axis=1)
            return {
                'akaze_descriptor_length': descriptors.shape[1] * 8,
                'akaze_descriptor_bit_ratio': np.mean(bit_counts),
                'akaze_descriptor_entropy': self._calculate_entropy(bit_counts.flatten()),
                'akaze_descriptor_diversity': self._calculate_binary_diversity(descriptors)
            }
        else:
            # Descriptores de punto flotante
            return {
                'akaze_descriptor_length': descriptors.shape[1],
                'akaze_descriptor_mean': np.mean(descriptors),
                'akaze_descriptor_std': np.std(descriptors),
                'akaze_descriptor_sparsity': np.sum(np.abs(descriptors) < 0.01) / descriptors.size,
                'akaze_descriptor_energy': np.sum(descriptors ** 2)
            }
    
    def _analizar_estabilidad_multiescala(self, keypoints, imagen):
        """Analiza estabilidad de puntos clave a trav√©s de escalas."""
        if not keypoints:
            return {
                'akaze_scale_stability': 0,
                'akaze_response_consistency': 0
            }
        
        # Agrupar puntos por octava
        octave_groups = {}
        for kp in keypoints:
            octave = kp.octave & 0xFF
            if octave not in octave_groups:
                octave_groups[octave] = []
            octave_groups[octave].append(kp)
        
        # Calcular estabilidad como consistencia entre escalas
        if len(octave_groups) > 1:
            responses_by_octave = []
            for octave, kps in octave_groups.items():
                avg_response = np.mean([kp.response for kp in kps])
                responses_by_octave.append(avg_response)
            
            stability = 1.0 / (np.std(responses_by_octave) + 1e-10)
            consistency = np.corrcoef(range(len(responses_by_octave)), responses_by_octave)[0, 1]
            consistency = consistency if not np.isnan(consistency) else 0
        else:
            stability = 1.0
            consistency = 1.0
        
        return {
            'akaze_scale_stability': stability,
            'akaze_response_consistency': consistency
        }
    
    def _calcular_coherencia_bordes(self, imagen, mask):
        """Calcula coherencia entre bordes y segmentaci√≥n."""
        # Detectar bordes
        if len(imagen.shape) == 3:
            imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
        else:
            imagen_gris = imagen.copy()
        
        edges = cv2.Canny(imagen_gris, 50, 150)
        
        # Calcular bordes de la m√°scara
        mask_edges = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
        
        # Coherencia como superposici√≥n de bordes
        overlap = np.sum((edges > 0) & (mask_edges > 0))
        total_mask_edges = np.sum(mask_edges > 0)
        
        return overlap / (total_mask_edges + 1e-10)
    
    def _analizar_consistencia_escalas(self, log_responses):
        """Analiza consistencia entre escalas en LoG."""
        if len(log_responses) < 2:
            return {'log_scale_consistency': 0}
        
        # Calcular correlaci√≥n entre escalas adyacentes
        correlations = []
        for i in range(len(log_responses) - 1):
            corr = np.corrcoef(log_responses[i].flatten(), log_responses[i+1].flatten())[0, 1]
            if not np.isnan(corr):
                correlations.append(abs(corr))
        
        consistency = np.mean(correlations) if correlations else 0
        return {'log_scale_consistency': consistency}
    
    def _calcular_coherencia_flujo(self, flow):
        """Calcula coherencia espacial del flujo √≥ptico."""
        # Calcular divergencia del campo de flujo
        u = flow[:, :, 0]
        v = flow[:, :, 1]
        
        # Gradientes
        du_dx = np.gradient(u, axis=1)
        dv_dy = np.gradient(v, axis=0)
        
        # Divergencia
        divergence = du_dx + dv_dy
        
        # Coherencia como inverso de la varianza de la divergencia
        coherence = 1.0 / (np.std(divergence) + 1e-10)
        
        return coherence
    
    def _get_empty_freak_stats(self):
        """Estad√≠sticas vac√≠as para FREAK."""
        return {
            'freak_num_keypoints': 0, 'freak_kp_mean_x': 0, 'freak_kp_std_x': 0,
            'freak_kp_mean_y': 0, 'freak_kp_std_y': 0, 'freak_kp_mean_size': 0,
            'freak_kp_std_size': 0, 'freak_kp_mean_response': 0, 'freak_kp_density': 0,
            'freak_bit_ratio': 0, 'freak_bit_entropy': 0, 'freak_descriptor_diversity': 0,
            'freak_pattern_complexity': 0, 'retina_center_density': 0,
            'retina_mid_density': 0, 'retina_periphery_density': 0, 'retina_radial_gradient': 0
        }
    
    def _get_empty_akaze_stats(self):
        """Estad√≠sticas vac√≠as para AKAZE."""
        return {
            'akaze_num_keypoints': 0, 'akaze_kp_mean_x': 0, 'akaze_kp_std_x': 0,
            'akaze_kp_mean_y': 0, 'akaze_kp_std_y': 0, 'akaze_kp_mean_size': 0,
            'akaze_kp_std_size': 0, 'akaze_kp_mean_response': 0, 'akaze_kp_std_response': 0,
            'akaze_kp_density': 0, 'akaze_num_scales': 0, 'akaze_scale_entropy': 0,
            'akaze_dominant_scale': 0, 'akaze_mean_angle': 0, 'akaze_std_angle': 0,
            'akaze_angle_entropy': 0, 'akaze_descriptor_length': 0,
            'akaze_scale_stability': 0, 'akaze_response_consistency': 0
        }
    
    def _get_empty_grabcut_stats(self):
        """Estad√≠sticas vac√≠as para GrabCut."""
        return {
            'grabcut_foreground_ratio': 0, 'grabcut_background_ratio': 1,
            'grabcut_num_regions': 0, 'grabcut_largest_region_area': 0,
            'grabcut_mean_region_area': 0, 'grabcut_std_region_area': 0,
            'grabcut_region_compactness': 0, 'grabcut_region_solidity': 0,
            'grabcut_centroid_mean_x': 0, 'grabcut_centroid_std_x': 0,
            'grabcut_centroid_mean_y': 0, 'grabcut_centroid_std_y': 0,
            'grabcut_edge_coherence': 0
        }
    
    # M√©todos de visualizaci√≥n
    def _visualizar_freak(self, resultados):
        """Visualiza resultados FREAK."""
        fig, axes = plt.subplots(1, 2, figsize=(15, 8))
        
        axes[0].imshow(resultados['gray_image'], cmap='gray')
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')
        
        img_kp = resultados['gray_image'].copy()
        if resultados['keypoints']:
            img_kp = cv2.drawKeypoints(img_kp, resultados['keypoints'], None,
                                     color=(0, 0, 255), 
                                     flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        
        axes[1].imshow(img_kp, cmap='gray')
        axes[1].set_title(f'Puntos Clave FREAK ({resultados.get("freak_num_keypoints", 0)})')
        axes[1].axis('off')
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"freak_visualization_{resultados['nombre_imagen']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è Visualizaci√≥n FREAK guardada: {imagen_filename}")
        
        plt.show()
    
    def _visualizar_akaze(self, resultados):
        """Visualiza resultados AKAZE."""
        fig, axes = plt.subplots(1, 2, figsize=(15, 8))
        
        axes[0].imshow(resultados['gray_image'], cmap='gray')
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')
        
        img_kp = resultados['gray_image'].copy()
        if resultados['keypoints']:
            img_kp = cv2.drawKeypoints(img_kp, resultados['keypoints'], None,
                                     color=(0, 0, 255), 
                                     flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        
        axes[1].imshow(img_kp, cmap='gray')
        axes[1].set_title(f'Puntos Clave AKAZE ({resultados.get("akaze_num_keypoints", 0)})')
        axes[1].axis('off')
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"akaze_visualization_{resultados['nombre_imagen']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è Visualizaci√≥n AKAZE guardada: {imagen_filename}")
        
        plt.show()
    
    def _visualizar_grabcut(self, resultados):
        """Visualiza resultados GrabCut."""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        # Imagen original
        if len(resultados['original_image'].shape) == 3:
            img_rgb = cv2.cvtColor(resultados['original_image'], cv2.COLOR_BGR2RGB)
            axes[0].imshow(img_rgb)
        else:
            axes[0].imshow(resultados['original_image'], cmap='gray')
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')
        
        # M√°scara de segmentaci√≥n
        axes[1].imshow(resultados['segmentation_mask'], cmap='gray')
        axes[1].set_title('Segmentaci√≥n GrabCut')
        axes[1].axis('off')
        
        # Imagen segmentada
        if len(resultados['original_image'].shape) == 3:
            segmented = resultados['original_image'].copy()
            segmented[resultados['segmentation_mask'] == 0] = 0
            segmented_rgb = cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB)
            axes[2].imshow(segmented_rgb)
        else:
            segmented = resultados['original_image'] * resultados['segmentation_mask']
            axes[2].imshow(segmented, cmap='gray')
        axes[2].set_title('Resultado Segmentado')
        axes[2].axis('off')
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"grabcut_visualization_{resultados['nombre_imagen']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è Visualizaci√≥n GrabCut guardada: {imagen_filename}")
        
        plt.show()
    
    def _visualizar_log(self, resultados):
        """Visualiza resultados LoG."""
        num_scales = len(resultados['log_responses'])
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        # Imagen original
        axes[0].imshow(resultados['gray_image'], cmap='gray')
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')
        
        # Respuestas LoG para diferentes sigmas
        for i, (sigma, response) in enumerate(zip(self.config['log']['sigma_values'], resultados['log_responses'])):
            if i + 1 < len(axes):
                axes[i + 1].imshow(np.abs(response), cmap='hot')
                axes[i + 1].set_title(f'LoG œÉ={sigma}')
                axes[i + 1].axis('off')
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"log_visualization_{resultados['nombre_imagen']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è Visualizaci√≥n LoG guardada: {imagen_filename}")
        
        plt.show()
    
    def _visualizar_optical_flow(self, resultados):
        """Visualiza resultados de flujo √≥ptico."""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Imagen 1
        axes[0, 0].imshow(resultados['image1'], cmap='gray')
        axes[0, 0].set_title('Imagen 1')
        axes[0, 0].axis('off')
        
        # Imagen 2
        axes[0, 1].imshow(resultados['image2'], cmap='gray')
        axes[0, 1].set_title('Imagen 2')
        axes[0, 1].axis('off')
        
        # Magnitud del flujo
        axes[1, 0].imshow(resultados['magnitude'], cmap='hot')
        axes[1, 0].set_title('Magnitud del Flujo')
        axes[1, 0].axis('off')
        
        # Campo de flujo visualizado
        step = 20
        h, w = resultados['image1'].shape[:2]
        
        # Crear grilla de coordenadas alineada con el submuestreo del flujo
        y_coords = np.arange(step//2, h, step)
        x_coords = np.arange(step//2, w, step)
        
        # Asegurar que no excedamos las dimensiones del flujo
        y_coords = y_coords[y_coords < h]
        x_coords = x_coords[x_coords < w]
        
        # Crear meshgrid
        x, y = np.meshgrid(x_coords, y_coords)
        
        # Extraer componentes del flujo con las mismas dimensiones
        u = resultados['flow_field'][y_coords[:, np.newaxis], x_coords, 0]
        v = resultados['flow_field'][y_coords[:, np.newaxis], x_coords, 1]
        
        # Asegurar que las dimensiones coincidan
        if u.shape != x.shape:
            # Redimensionar para que coincidan
            min_rows = min(u.shape[0], x.shape[0])
            min_cols = min(u.shape[1], x.shape[1])
            u = u[:min_rows, :min_cols]
            v = v[:min_rows, :min_cols]
            x = x[:min_rows, :min_cols]
            y = y[:min_rows, :min_cols]
        
        axes[1, 1].imshow(resultados['image1'], cmap='gray', alpha=0.8)
        
        # Solo dibujar si tenemos datos v√°lidos
        if u.size > 0 and v.size > 0:
            axes[1, 1].quiver(x, y, u, v, color='red', alpha=0.8, scale_units='xy', scale=1)
        
        axes[1, 1].set_title('Campo de Flujo √ìptico')
        axes[1, 1].axis('off')
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"optical_flow_visualization_{resultados['nombre_imagen']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è Visualizaci√≥n Optical Flow guardada: {imagen_filename}")
        
        plt.show()
    
    def _visualizar_optical_flow_profesora(self, resultados):
        """Visualiza resultados de optical flow usando exactamente el m√©todo de la profesora."""
        # Implementaci√≥n exacta del c√≥digo de visualizaci√≥n de la profesora
        plt.figure(figsize=(15, 5))
        
        plt.subplot(1, 3, 1)
        plt.imshow(resultados['frame1'], cmap='gray')
        plt.title('Frame 1')
        plt.axis('off')
        
        plt.subplot(1, 3, 2)
        plt.imshow(resultados['frame2'], cmap='gray')
        plt.title('Frame 2')
        plt.axis('off')
        
        plt.subplot(1, 3, 3)
        plt.title('Optical Flow (HSV)')
        plt.imshow(resultados['flow_rgb'])
        plt.axis('off')
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"optical_flow_profesora_{resultados['nombre_imagen']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è Visualizaci√≥n Optical Flow (Profesora) guardada: {imagen_filename}")
        
        plt.show()
        
        # Mostrar estad√≠sticas como en el c√≥digo original
        print("‚úÖ Optical Flow b√°sico completado")
        print(f"üìä Magnitud promedio del flujo: {resultados['optical_flow_mean_magnitude']:.4f}")
        print(f"üìä Magnitud m√°xima: {resultados['optical_flow_max_magnitude']:.4f}")
    
    def _visualizar_secuencia_imagenes(self, resultados):
        """Visualiza el an√°lisis de secuencia de im√°genes."""
        estadisticas = resultados['estadisticas_secuencia']
        cambios = resultados['cambios_movimiento']
        analisis_global = resultados['analisis_global']
        
        if not estadisticas:
            print("‚ö†Ô∏è No hay estad√≠sticas para visualizar")
            return
        
        # Crear visualizaci√≥n completa
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        # Extraer datos para gr√°ficos
        indices = [stat['indice'] for stat in estadisticas]
        magnitudes = [stat['magnitude_mean'] for stat in estadisticas]
        intensidades = [stat['movement_intensity'] for stat in estadisticas]
        areas_movimiento = [stat['movement_area'] for stat in estadisticas]
        magnitudes_max = [stat['magnitude_max'] for stat in estadisticas]
        
        # 1. Magnitud promedio a lo largo de la secuencia
        axes[0].plot(indices, magnitudes, 'b-', linewidth=2, marker='o', markersize=4)
        axes[0].set_title('Magnitud de Movimiento en la Secuencia')
        axes[0].set_xlabel('√çndice de Transici√≥n')
        axes[0].set_ylabel('Magnitud Promedio')
        axes[0].grid(True, alpha=0.3)
        
        # Marcar cambios significativos
        if cambios:
            cambio_indices = [c['posicion'] for c in cambios]
            cambio_magnitudes = [magnitudes[c['posicion']-1] for c in cambios if c['posicion']-1 < len(magnitudes)]
            axes[0].scatter(cambio_indices, cambio_magnitudes, color='red', s=100, alpha=0.8, 
                          label=f'Cambios Significativos ({len(cambios)})')
            axes[0].legend()
        
        # 2. Intensidad de movimiento
        axes[1].bar(indices, intensidades, alpha=0.7, color='green', edgecolor='black')
        axes[1].set_title('Intensidad de Movimiento')
        axes[1].set_xlabel('√çndice de Transici√≥n')
        axes[1].set_ylabel('P√≠xeles en Movimiento')
        axes[1].grid(True, alpha=0.3)
        
        # 3. √Årea de movimiento significativo
        axes[2].fill_between(indices, areas_movimiento, alpha=0.6, color='orange')
        axes[2].set_title('√Årea de Movimiento Significativo')
        axes[2].set_xlabel('√çndice de Transici√≥n')
        axes[2].set_ylabel('P√≠xeles')
        axes[2].grid(True, alpha=0.3)
        
        # 4. Comparaci√≥n magnitud promedio vs m√°xima
        axes[3].plot(indices, magnitudes, 'b-', label='Magnitud Promedio', linewidth=2)
        axes[3].plot(indices, magnitudes_max, 'r--', label='Magnitud M√°xima', linewidth=2)
        axes[3].set_title('Comparaci√≥n de Magnitudes')
        axes[3].set_xlabel('√çndice de Transici√≥n')
        axes[3].set_ylabel('Magnitud')
        axes[3].legend()
        axes[3].grid(True, alpha=0.3)
        
        # 5. Histograma de magnitudes
        axes[4].hist(magnitudes, bins=15, alpha=0.7, color='purple', edgecolor='black')
        axes[4].axvline(np.mean(magnitudes), color='red', linestyle='--', 
                       label=f'Promedio: {np.mean(magnitudes):.3f}')
        axes[4].set_title('Distribuci√≥n de Magnitudes')
        axes[4].set_xlabel('Magnitud')
        axes[4].set_ylabel('Frecuencia')
        axes[4].legend()
        axes[4].grid(True, alpha=0.3)
        
        # 6. Resumen de cambios detectados
        if cambios:
            tipos_cambio = [c['tipo'] for c in cambios]
            incrementos = tipos_cambio.count('incremento')
            reducciones = tipos_cambio.count('reduccion')
            
            axes[5].pie([incrementos, reducciones], 
                       labels=[f'Incrementos ({incrementos})', f'Reducciones ({reducciones})'],
                       autopct='%1.1f%%', startangle=90, colors=['lightgreen', 'lightcoral'])
            axes[5].set_title('Tipos de Cambios Detectados')
        else:
            axes[5].text(0.5, 0.5, 'No se detectaron\ncambios significativos', 
                        ha='center', va='center', transform=axes[5].transAxes, fontsize=12)
            axes[5].set_title('Cambios Detectados')
        
        plt.tight_layout()
        
        # Guardar visualizaci√≥n si se especifica
        if hasattr(self, '_save_visualization') and self._save_visualization:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            imagen_filename = os.path.join(self.results_dir, f"secuencia_analysis_{resultados['nombre_secuencia']}_{timestamp}.png")
            self.asegurar_directorio_existe(imagen_filename)
            plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
            print(f"üñºÔ∏è An√°lisis de secuencia guardado: {imagen_filename}")
        
        plt.show()
        
        # Mostrar resumen textual
        print(f"\nüìä RESUMEN DEL AN√ÅLISIS DE SECUENCIA")
        print("=" * 60)
        print(f"üìÅ Carpeta: {os.path.basename(resultados['carpeta_path'])}")
        print(f"üñºÔ∏è Im√°genes procesadas: {len(resultados['archivos_procesados'])}")
        print(f"üîÑ Transiciones analizadas: {analisis_global['transiciones_procesadas']}")
        print(f"üìà Tendencia general: {analisis_global['tendencia_general'].upper()}")
        print(f"üìä Estabilidad: {analisis_global['estabilidad']}")
        print(f"üìâ Variabilidad: {analisis_global['variabilidad']:.3f}")
        print(f"‚ö° Cambios significativos: {analisis_global['num_cambios_significativos']}")
        print(f"üîù Picos detectados: {analisis_global['num_picos']}")
        print(f"üîΩ Valles detectados: {analisis_global['num_valles']}")
        print(f"üîÑ Periodicidad: {'S√ç' if analisis_global['periodicidad_detectada'] else 'NO'}")
        print(f"üìè Magnitud promedio: {analisis_global['magnitude_promedio']:.4f}")
        print(f"üìè Rango: {analisis_global['magnitude_min']:.4f} - {analisis_global['magnitude_max']:.4f}")
        print("=" * 60)

    def guardar_resultados(self, formato='csv'):
        """Guarda los resultados del an√°lisis."""
        if not self.current_results:
            print("‚ùå No hay resultados para guardar.")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if formato.lower() == 'csv':
            df = pd.DataFrame(self.current_results)
            archivo_csv = os.path.join(self.results_dir, f'advanced_analysis_{timestamp}.csv')
            os.makedirs(os.path.dirname(archivo_csv), exist_ok=True)
            df.to_csv(archivo_csv, index=False)
            print(f"üíæ Resultados CSV guardados: {archivo_csv}")
        
        elif formato.lower() == 'json':
            import json
            archivo_json = os.path.join(self.results_dir, f'advanced_analysis_{timestamp}.json')
            os.makedirs(os.path.dirname(archivo_json), exist_ok=True)
            with open(archivo_json, 'w', encoding='utf-8') as f:
                json.dump(self.current_results, f, indent=2, ensure_ascii=False, default=str)
            print(f"üíæ Resultados JSON guardados: {archivo_json}")
    
    def generar_reporte_avanzado(self):
        """Genera reporte del an√°lisis avanzado."""
        if not self.current_results:
            print("‚ùå No hay resultados para el reporte.")
            return
        
        print("\nüìã REPORTE AN√ÅLISIS ALGORITMOS AVANZADOS")
        print("=" * 50)
        print(f"üìä Im√°genes analizadas: {len(self.current_results)}")
        
        # Estad√≠sticas por algoritmo
        algoritmos = ['freak', 'akaze', 'grabcut', 'log', 'optical_flow']
        
        for algoritmo in algoritmos:
            keypoints_key = f'{algoritmo}_num_keypoints'
            if algoritmo == 'grabcut':
                keypoints_key = 'grabcut_num_regions'
            elif algoritmo == 'log':
                keypoints_key = 'log_num_blobs'
            elif algoritmo == 'optical_flow':
                keypoints_key = 'optical_flow_mean_magnitude'
            
            valores = [r.get(keypoints_key, 0) for r in self.current_results]
            if any(valores):
                print(f"\nüîç {algoritmo.upper()}:")
                print(f"   Promedio: {np.mean(valores):.2f}")
                print(f"   Desviaci√≥n: {np.std(valores):.2f}")
                print(f"   M√°ximo: {np.max(valores):.2f}")
        
        print("\n" + "=" * 50)
    
    def _guardar_resultados_freak(self, resultados, nombre_imagen):
        """Guarda los resultados FREAK en archivos CSV y TXT."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Archivo CSV con estad√≠sticas principales
        csv_filename = os.path.join(self.results_dir, f"freak_analysis_{nombre_imagen}_{timestamp}.csv")
        self.asegurar_directorio_existe(csv_filename)
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['M√©trica', 'Valor'])
            
            # Estad√≠sticas b√°sicas
            writer.writerow(['Algoritmo', 'FREAK' if resultados.get('freak_algorithm_available', False) else 'ORB (Fallback)'])
            writer.writerow(['Puntos clave detectados', resultados.get('freak_num_keypoints', 0)])
            writer.writerow(['Densidad de puntos', f"{resultados.get('freak_kp_density', 0):.8f}"])
            writer.writerow(['Ubicaci√≥n promedio X', f"{resultados.get('freak_kp_mean_x', 0):.2f}"])
            writer.writerow(['Ubicaci√≥n promedio Y', f"{resultados.get('freak_kp_mean_y', 0):.2f}"])
            writer.writerow(['Tama√±o promedio', f"{resultados.get('freak_kp_mean_size', 0):.2f}"])
            writer.writerow(['Respuesta promedio', f"{resultados.get('freak_kp_mean_response', 0):.6f}"])
            writer.writerow(['Ratio de bits activos', f"{resultados.get('freak_bit_ratio', 0):.4f}"])
            writer.writerow(['Entrop√≠a de bits', f"{resultados.get('freak_bit_entropy', 0):.4f}"])
            writer.writerow(['Diversidad de descriptores', f"{resultados.get('freak_descriptor_diversity', 0):.4f}"])
            writer.writerow(['Complejidad de patr√≥n', f"{resultados.get('freak_pattern_complexity', 0):.4f}"])
            writer.writerow(['Densidad centro retina', f"{resultados.get('retina_center_density', 0):.4f}"])
            writer.writerow(['Densidad periferia retina', f"{resultados.get('retina_periphery_density', 0):.4f}"])
        
        # Archivo TXT con informaci√≥n detallada
        txt_filename = os.path.join(self.results_dir, f"freak_detailed_{nombre_imagen}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write("AN√ÅLISIS DETALLADO FREAK\n")
            txtfile.write("=" * 50 + "\n\n")
            txtfile.write(f"Imagen analizada: {nombre_imagen}\n")
            txtfile.write(f"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            txtfile.write(f"Algoritmo disponible: {'S√≠' if resultados.get('freak_algorithm_available', False) else 'No (usando ORB)'}\n\n")
            
            # Estad√≠sticas de puntos clave
            keypoints = resultados.get('keypoints', [])
            txtfile.write(f"PUNTOS CLAVE DETECTADOS: {len(keypoints)}\n")
            txtfile.write("-" * 30 + "\n")
            
            for i, kp in enumerate(keypoints[:10]):  # Primeros 10 puntos
                txtfile.write(f"Punto {i+1}:\n")
                txtfile.write(f"  Posici√≥n: ({kp.pt[0]:.2f}, {kp.pt[1]:.2f})\n")
                txtfile.write(f"  Tama√±o: {kp.size:.2f}\n")
                txtfile.write(f"  √Ångulo: {kp.angle:.2f}¬∞\n")
                txtfile.write(f"  Respuesta: {kp.response:.6f}\n\n")
            
            if len(keypoints) > 10:
                txtfile.write(f"... y {len(keypoints) - 10} puntos m√°s\n\n")
        
        print(f"üíæ Resultados FREAK guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
    
    def _guardar_resultados_akaze(self, resultados, nombre_imagen):
        """Guarda los resultados AKAZE en archivos CSV y TXT."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Similar estructura para AKAZE
        csv_filename = os.path.join(self.results_dir, f"akaze_analysis_{nombre_imagen}_{timestamp}.csv")
        self.asegurar_directorio_existe(csv_filename)
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['M√©trica', 'Valor'])
            
            writer.writerow(['Algoritmo', 'AKAZE'])
            writer.writerow(['Puntos clave detectados', resultados.get('akaze_num_keypoints', 0)])
            writer.writerow(['Densidad de puntos', f"{resultados.get('akaze_kp_density', 0):.8f}"])
            writer.writerow(['Ubicaci√≥n promedio X', f"{resultados.get('akaze_kp_mean_x', 0):.2f}"])
            writer.writerow(['Ubicaci√≥n promedio Y', f"{resultados.get('akaze_kp_mean_y', 0):.2f}"])
            writer.writerow(['Tama√±o promedio', f"{resultados.get('akaze_kp_mean_size', 0):.2f}"])
            writer.writerow(['Respuesta promedio', f"{resultados.get('akaze_kp_mean_response', 0):.6f}"])
            writer.writerow(['N√∫mero de escalas', resultados.get('akaze_num_scales', 0)])
            writer.writerow(['Entrop√≠a de escalas', f"{resultados.get('akaze_scale_entropy', 0):.4f}"])
            writer.writerow(['Estabilidad multi-escala', f"{resultados.get('akaze_scale_stability', 0):.4f}"])
        
        txt_filename = os.path.join(self.results_dir, f"akaze_detailed_{nombre_imagen}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write("AN√ÅLISIS DETALLADO AKAZE\n")
            txtfile.write("=" * 50 + "\n\n")
            txtfile.write(f"Imagen analizada: {nombre_imagen}\n")
            txtfile.write(f"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            keypoints = resultados.get('keypoints', [])
            txtfile.write(f"PUNTOS CLAVE DETECTADOS: {len(keypoints)}\n")
            txtfile.write("-" * 30 + "\n")
            
            for i, kp in enumerate(keypoints[:10]):
                txtfile.write(f"Punto {i+1}:\n")
                txtfile.write(f"  Posici√≥n: ({kp.pt[0]:.2f}, {kp.pt[1]:.2f})\n")
                txtfile.write(f"  Tama√±o: {kp.size:.2f}\n")
                txtfile.write(f"  √Ångulo: {kp.angle:.2f}¬∞\n")
                txtfile.write(f"  Respuesta: {kp.response:.6f}\n")
                txtfile.write(f"  Octava: {kp.octave}\n\n")
        
        print(f"üíæ Resultados AKAZE guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
    
    def _guardar_resultados_grabcut(self, resultados, nombre_imagen):
        """Guarda los resultados GrabCut en archivos CSV y TXT."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        csv_filename = os.path.join(self.results_dir, f"grabcut_analysis_{nombre_imagen}_{timestamp}.csv")
        self.asegurar_directorio_existe(csv_filename)
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['M√©trica', 'Valor'])
            
            writer.writerow(['Algoritmo', 'GrabCut'])
            writer.writerow(['Ratio primer plano', f"{resultados.get('grabcut_foreground_ratio', 0):.6f}"])
            writer.writerow(['Ratio fondo', f"{resultados.get('grabcut_background_ratio', 0):.6f}"])
            writer.writerow(['N√∫mero de regiones', resultados.get('grabcut_num_regions', 0)])
            writer.writerow(['√Årea regi√≥n m√°s grande', resultados.get('grabcut_largest_region_area', 0)])
            writer.writerow(['√Årea promedio regiones', f"{resultados.get('grabcut_mean_region_area', 0):.2f}"])
            writer.writerow(['Compacidad promedio', f"{resultados.get('grabcut_region_compactness', 0):.4f}"])
            writer.writerow(['Solidez promedio', f"{resultados.get('grabcut_region_solidity', 0):.4f}"])
            writer.writerow(['Coherencia de bordes', f"{resultados.get('grabcut_edge_coherence', 0):.4f}"])
        
        txt_filename = os.path.join(self.results_dir, f"grabcut_detailed_{nombre_imagen}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write("AN√ÅLISIS DETALLADO GRABCUT\n")
            txtfile.write("=" * 50 + "\n\n")
            txtfile.write(f"Imagen analizada: {nombre_imagen}\n")
            txtfile.write(f"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            txtfile.write("ESTAD√çSTICAS DE SEGMENTACI√ìN:\n")
            txtfile.write("-" * 30 + "\n")
            txtfile.write(f"Iteraciones GrabCut: {self.config['grabcut']['iterations']}\n")
            txtfile.write(f"P√≠xeles de primer plano: {int(resultados.get('grabcut_foreground_ratio', 0) * resultados['original_image'].size)}\n")
            txtfile.write(f"P√≠xeles de fondo: {int(resultados.get('grabcut_background_ratio', 0) * resultados['original_image'].size)}\n")
            txtfile.write(f"N√∫mero de regiones conectadas: {resultados.get('grabcut_num_regions', 0)}\n")
        
        print(f"üíæ Resultados GrabCut guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
    
    def _guardar_resultados_log(self, resultados, nombre_imagen):
        """Guarda los resultados LoG en archivos CSV y TXT."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        csv_filename = os.path.join(self.results_dir, f"log_analysis_{nombre_imagen}_{timestamp}.csv")
        self.asegurar_directorio_existe(csv_filename)
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['M√©trica', 'Valor'])
            
            writer.writerow(['Algoritmo', 'Laplaciano de Gauss (LoG)'])
            writer.writerow(['N√∫mero de blobs', resultados.get('log_num_blobs', 0)])
            writer.writerow(['Densidad de blobs', f"{resultados.get('log_blob_density', 0):.8f}"])
            writer.writerow(['Ubicaci√≥n promedio X', f"{resultados.get('log_mean_x', 0):.2f}"])
            writer.writerow(['Ubicaci√≥n promedio Y', f"{resultados.get('log_mean_y', 0):.2f}"])
            writer.writerow(['Sigma promedio', f"{resultados.get('log_mean_sigma', 0):.2f}"])
            writer.writerow(['Respuesta promedio', f"{resultados.get('log_mean_response', 0):.6f}"])
            writer.writerow(['Consistencia escalas', f"{resultados.get('log_scale_consistency', 0):.4f}"])
        
        txt_filename = os.path.join(self.results_dir, f"log_detailed_{nombre_imagen}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write("AN√ÅLISIS DETALLADO LAPLACIANO DE GAUSS (LoG)\n")
            txtfile.write("=" * 60 + "\n\n")
            txtfile.write(f"Imagen analizada: {nombre_imagen}\n")
            txtfile.write(f"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            txtfile.write("CONFIGURACI√ìN DEL ALGORITMO:\n")
            txtfile.write("-" * 35 + "\n")
            txtfile.write(f"Valores sigma analizados: {self.config['log']['sigma_values']}\n")
            txtfile.write(f"Factor de umbral: {self.config['log']['threshold_factor']}\n")
            txtfile.write(f"N√∫mero total de blobs detectados: {resultados.get('log_num_blobs', 0)}\n")
            txtfile.write(f"Densidad de blobs: {resultados.get('log_blob_density', 0):.8f}\n")
            txtfile.write(f"Consistencia entre escalas: {resultados.get('log_scale_consistency', 0):.4f}\n\n")
            
            # Estad√≠sticas por escala
            txtfile.write("ESTAD√çSTICAS POR ESCALA:\n")
            txtfile.write("-" * 30 + "\n")
            for sigma in self.config['log']['sigma_values']:
                txtfile.write(f"Sigma {sigma}:\n")
                media_key = f'log_sigma_{sigma}_mean'
                std_key = f'log_sigma_{sigma}_std'
                energia_key = f'log_sigma_{sigma}_energy'
                entropia_key = f'log_sigma_{sigma}_entropy'
                
                txtfile.write(f"  Media: {resultados.get(media_key, 0):.6f}\n")
                txtfile.write(f"  Desviaci√≥n est√°ndar: {resultados.get(std_key, 0):.6f}\n")
                txtfile.write(f"  Energ√≠a: {resultados.get(energia_key, 0):.6f}\n")
                txtfile.write(f"  Entrop√≠a: {resultados.get(entropia_key, 0):.6f}\n\n")
            
            # Estad√≠sticas de distribuci√≥n de blobs
            if resultados.get('log_num_blobs', 0) > 0:
                txtfile.write("ESTAD√çSTICAS DE DISTRIBUCI√ìN DE BLOBS:\n")
                txtfile.write("-" * 40 + "\n")
                txtfile.write(f"Posici√≥n promedio X: {resultados.get('log_mean_x', 0):.2f} ¬± {resultados.get('log_std_x', 0):.2f}\n")
                txtfile.write(f"Posici√≥n promedio Y: {resultados.get('log_mean_y', 0):.2f} ¬± {resultados.get('log_std_y', 0):.2f}\n")
                txtfile.write(f"Sigma promedio: {resultados.get('log_mean_sigma', 0):.2f} ¬± {resultados.get('log_std_sigma', 0):.2f}\n")
                txtfile.write(f"Respuesta promedio: {resultados.get('log_mean_response', 0):.6f} ¬± {resultados.get('log_std_response', 0):.6f}\n\n")
            
            # Lista detallada de blobs detectados
            txtfile.write("BLOBS DETECTADOS (Primeros 20):\n")
            txtfile.write("-" * 35 + "\n")
            local_maxima = resultados.get('local_maxima', [])
            if local_maxima:
                for i, blob in enumerate(local_maxima[:20]):
                    try:
                        # Los blobs son diccionarios con claves 'x', 'y', 'sigma', 'response'
                        if isinstance(blob, dict):
                            x = float(blob.get('x', 0))
                            y = float(blob.get('y', 0))
                            sigma = float(blob.get('sigma', 0))
                            response = float(blob.get('response', 0))
                            
                            txtfile.write(f"Blob {i+1:2d}: Pos=({x:6.2f}, {y:6.2f}) Sigma={sigma:4.2f} Resp={response:8.6f}\n")
                        else:
                            txtfile.write(f"Blob {i+1:2d}: Formato inesperado - {blob}\n")
                    except (ValueError, TypeError) as e:
                        txtfile.write(f"Blob {i+1:2d}: Error de conversi√≥n - {blob}\n")
            else:
                txtfile.write("No se detectaron blobs.\n")
            
            if len(local_maxima) > 20:
                txtfile.write(f"\n... y {len(local_maxima) - 20} blobs adicionales.\n")
        
        print(f"üíæ Resultados LoG guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
    
    def _guardar_resultados_optical_flow(self, resultados, nombre_imagen):
        """Guarda los resultados Optical Flow en archivos CSV y TXT."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        csv_filename = os.path.join(self.results_dir, f"optical_flow_analysis_{nombre_imagen}_{timestamp}.csv")
        self.asegurar_directorio_existe(csv_filename)
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['M√©trica', 'Valor'])
            
            writer.writerow(['Algoritmo', 'Farneback Optical Flow'])
            writer.writerow(['Magnitud promedio', f"{resultados.get('optical_flow_mean_magnitude', 0):.6f}"])
            writer.writerow(['Magnitud m√°xima', f"{resultados.get('optical_flow_max_magnitude', 0):.6f}"])
            writer.writerow(['Desviaci√≥n magnitud', f"{resultados.get('optical_flow_std_magnitude', 0):.6f}"])
            writer.writerow(['√Ångulo promedio (rad)', f"{resultados.get('optical_flow_mean_angle', 0):.6f}"])
            writer.writerow(['√Ångulo promedio (grados)', f"{np.degrees(resultados.get('optical_flow_mean_angle', 0)):.2f}"])
            writer.writerow(['Direcci√≥n dominante', f"{resultados.get('optical_flow_dominant_direction', 0):.0f}¬∞"])
            writer.writerow(['Entrop√≠a direccional', f"{resultados.get('optical_flow_direction_entropy', 0):.4f}"])
            writer.writerow(['Ratio p√≠xeles en movimiento', f"{resultados.get('optical_flow_movement_ratio', 0):.4f}"])
            writer.writerow(['Coherencia espacial', f"{resultados.get('optical_flow_spatial_coherence', 0):.4f}"])
        
        txt_filename = os.path.join(self.results_dir, f"optical_flow_detailed_{nombre_imagen}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write("AN√ÅLISIS DETALLADO FLUJO √ìPTICO\n")
            txtfile.write("=" * 50 + "\n\n")
            txtfile.write(f"Imagen analizada: {nombre_imagen}\n")
            txtfile.write(f"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            txtfile.write("CONFIGURACI√ìN DEL ALGORITMO:\n")
            txtfile.write("-" * 30 + "\n")
            txtfile.write(f"Algoritmo: Farneback (Flujo √≥ptico denso)\n")
            txtfile.write(f"Escala piramidal: {self.config['optical_flow']['pyr_scale']}\n")
            txtfile.write(f"Niveles piramidales: {self.config['optical_flow']['levels']}\n")
            txtfile.write(f"Tama√±o de ventana: {self.config['optical_flow']['winsize']}\n")
            txtfile.write(f"Iteraciones: {self.config['optical_flow']['iterations']}\n")
            txtfile.write(f"Orden polinomial: {self.config['optical_flow']['poly_n']}\n")
            txtfile.write(f"Sigma polinomial: {self.config['optical_flow']['poly_sigma']}\n\n")
            
            txtfile.write("ESTAD√çSTICAS DE MOVIMIENTO:\n")
            txtfile.write("-" * 30 + "\n")
            txtfile.write(f"Campo de flujo calculado para imagen de dimensiones: {resultados['image1'].shape}\n")
            txtfile.write(f"Magnitud promedio del movimiento: {resultados.get('optical_flow_mean_magnitude', 0):.6f}\n")
            txtfile.write(f"Porcentaje de p√≠xeles en movimiento: {resultados.get('optical_flow_movement_ratio', 0)*100:.2f}%\n")
        
        print(f"üíæ Resultados Optical Flow guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
    
    def _guardar_resultados_optical_flow_profesora(self, resultados, nombre_imagen):
        """Guarda resultados del optical flow usando el m√©todo de la profesora."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Archivo CSV
        csv_filename = os.path.join(self.results_dir, f"optical_flow_profesora_{nombre_imagen}_{timestamp}.csv")
        self.asegurar_directorio_existe(csv_filename)
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['M√©trica', 'Valor'])
            writer.writerow(['Magnitud promedio', f"{resultados['optical_flow_mean_magnitude']:.6f}"])
            writer.writerow(['Magnitud m√°xima', f"{resultados['optical_flow_max_magnitude']:.6f}"])
            writer.writerow(['Desviaci√≥n est√°ndar magnitud', f"{resultados['optical_flow_std_magnitude']:.6f}"])
            writer.writerow(['√Ångulo promedio (radianes)', f"{resultados['optical_flow_mean_angle']:.6f}"])
            writer.writerow(['√Ångulo promedio (grados)', f"{np.degrees(resultados['optical_flow_mean_angle']):.2f}"])
            writer.writerow(['M√©todo', resultados['optical_flow_method']])
            
            # Par√°metros utilizados
            params = resultados['optical_flow_parameters']
            writer.writerow(['Par√°metro pyr_scale', params['pyr_scale']])
            writer.writerow(['Par√°metro levels', params['levels']])
            writer.writerow(['Par√°metro winsize', params['winsize']])
            writer.writerow(['Par√°metro iterations', params['iterations']])
            writer.writerow(['Par√°metro poly_n', params['poly_n']])
            writer.writerow(['Par√°metro poly_sigma', params['poly_sigma']])
        
        # Archivo TXT
        txt_filename = os.path.join(self.results_dir, f"optical_flow_profesora_{nombre_imagen}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write("AN√ÅLISIS OPTICAL FLOW - M√âTODO PROFESORA\n")
            txtfile.write("=" * 50 + "\n")
            txtfile.write(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            txtfile.write(f"Imagen analizada: {nombre_imagen}\n\n")
            
            txtfile.write("CONFIGURACI√ìN UTILIZADA:\n")
            txtfile.write("-" * 30 + "\n")
            txtfile.write("Algoritmo: Farneback Optical Flow\n")
            params = resultados['optical_flow_parameters']
            txtfile.write(f"‚Ä¢ Escala piramidal: {params['pyr_scale']}\n")
            txtfile.write(f"‚Ä¢ Niveles: {params['levels']}\n")
            txtfile.write(f"‚Ä¢ Tama√±o ventana: {params['winsize']}\n")
            txtfile.write(f"‚Ä¢ Iteraciones: {params['iterations']}\n")
            txtfile.write(f"‚Ä¢ Polinomio N: {params['poly_n']}\n")
            txtfile.write(f"‚Ä¢ Polinomio Sigma: {params['poly_sigma']}\n\n")
            
            txtfile.write("RESULTADOS:\n")
            txtfile.write("-" * 30 + "\n")
            txtfile.write(f"Magnitud promedio del flujo: {resultados['optical_flow_mean_magnitude']:.6f}\n")
            txtfile.write(f"Magnitud m√°xima: {resultados['optical_flow_max_magnitude']:.6f}\n")
            txtfile.write(f"Desviaci√≥n est√°ndar: {resultados['optical_flow_std_magnitude']:.6f}\n")
            txtfile.write(f"√Ångulo promedio: {np.degrees(resultados['optical_flow_mean_angle']):.2f}¬∞\n")
            txtfile.write(f"Dimensiones de imagen: {resultados['frame1'].shape}\n\n")
            
            txtfile.write("NOTA:\n")
            txtfile.write("Este an√°lisis fue realizado usando exactamente el mismo c√≥digo\n")
            txtfile.write("y par√°metros proporcionados por la profesora.\n")
        
        # Guardar imagen HSV del flujo
        imagen_filename = os.path.join(self.results_dir, f"optical_flow_hsv_{nombre_imagen}_{timestamp}.png")
        plt.figure(figsize=(10, 6))
        plt.imshow(resultados['flow_rgb'])
        plt.title(f'Optical Flow HSV - {nombre_imagen}')
        plt.axis('off')
        plt.savefig(imagen_filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        print("üíæ Resultados Optical Flow (M√©todo Profesora) guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
        print(f"   üñºÔ∏è Imagen HSV: {imagen_filename}")
    
    def _guardar_resultados_secuencia(self, resultados, nombre_secuencia):
        """Guarda resultados del an√°lisis de secuencia de im√°genes."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Crear directorio espec√≠fico para secuencias
        secuencia_dir = os.path.join(self.results_dir, "sequence_analysis")
        os.makedirs(secuencia_dir, exist_ok=True)
        
        # Archivo CSV con estad√≠sticas de transiciones
        csv_filename = os.path.join(secuencia_dir, f"sequence_analysis_{nombre_secuencia}_{timestamp}.csv")
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # Secci√≥n de an√°lisis global
            writer.writerow(['Tipo', 'M√©trica', 'Valor'])
            analisis = resultados['analisis_global']
            writer.writerow(['Global', 'Tendencia general', analisis['tendencia_general']])
            writer.writerow(['Global', 'Estabilidad', analisis['estabilidad']])
            writer.writerow(['Global', 'Variabilidad', f"{analisis['variabilidad']:.4f}"])
            writer.writerow(['Global', 'Magnitud promedio', f"{analisis['magnitude_promedio']:.6f}"])
            writer.writerow(['Global', 'Magnitud m√°xima', f"{analisis['magnitude_max']:.6f}"])
            writer.writerow(['Global', 'Magnitud m√≠nima', f"{analisis['magnitude_min']:.6f}"])
            writer.writerow(['Global', 'N√∫mero de picos', analisis['num_picos']])
            writer.writerow(['Global', 'N√∫mero de valles', analisis['num_valles']])
            writer.writerow(['Global', 'Cambios significativos', analisis['num_cambios_significativos']])
            writer.writerow(['Global', 'Periodicidad detectada', 'S√≠' if analisis['periodicidad_detectada'] else 'No'])
            
            # Estad√≠sticas por transici√≥n
            writer.writerow([])  # L√≠nea vac√≠a
            writer.writerow(['Transici√≥n', 'Imagen Anterior', 'Imagen Actual', 'Magnitud Media', 
                           'Magnitud M√°xima', 'Intensidad Movimiento', '√Årea Movimiento'])
            
            for stat in resultados['estadisticas_secuencia']:
                writer.writerow([
                    stat['indice'],
                    stat['imagen_anterior'],
                    stat['imagen_actual'],
                    f"{stat['magnitude_mean']:.6f}",
                    f"{stat['magnitude_max']:.6f}",
                    stat['movement_intensity'],
                    stat['movement_area']
                ])
            
            # Cambios detectados
            if resultados['cambios_movimiento']:
                writer.writerow([])  # L√≠nea vac√≠a
                writer.writerow(['Cambio', 'Posici√≥n', 'Tipo', 'Magnitud Anterior', 'Magnitud Actual', 'Cambio Relativo'])
                
                for i, cambio in enumerate(resultados['cambios_movimiento']):
                    writer.writerow([
                        i + 1,
                        cambio['posicion'],
                        cambio['tipo'],
                        f"{cambio['magnitude_anterior']:.6f}",
                        f"{cambio['magnitude_actual']:.6f}",
                        f"{cambio['cambio_relativo']:.4f}"
                    ])
        
        # Archivo TXT con an√°lisis detallado
        txt_filename = os.path.join(secuencia_dir, f"sequence_analysis_{nombre_secuencia}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write("AN√ÅLISIS DE SECUENCIA DE IM√ÅGENES\n")
            txtfile.write("=" * 60 + "\n")
            txtfile.write(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            txtfile.write(f"Carpeta analizada: {resultados['carpeta_path']}\n")
            txtfile.write(f"Secuencia: {nombre_secuencia}\n\n")
            
            # Informaci√≥n general
            txtfile.write("INFORMACI√ìN GENERAL:\n")
            txtfile.write("-" * 30 + "\n")
            txtfile.write(f"N√∫mero de im√°genes: {len(resultados['archivos_procesados'])}\n")
            txtfile.write(f"Transiciones analizadas: {resultados['num_transiciones']}\n")
            txtfile.write(f"Algoritmo: Farneback Optical Flow\n\n")
            
            # An√°lisis global
            txtfile.write("AN√ÅLISIS GLOBAL:\n")
            txtfile.write("-" * 30 + "\n")
            analisis = resultados['analisis_global']
            txtfile.write(f"Tendencia general: {analisis['tendencia_general'].upper()}\n")
            txtfile.write(f"Estabilidad de la secuencia: {analisis['estabilidad']}\n")
            txtfile.write(f"Variabilidad: {analisis['variabilidad']:.4f}\n")
            txtfile.write(f"Magnitud promedio: {analisis['magnitude_promedio']:.6f}\n")
            txtfile.write(f"Rango de magnitudes: {analisis['magnitude_min']:.6f} - {analisis['magnitude_max']:.6f}\n")
            txtfile.write(f"Picos detectados: {analisis['num_picos']} en posiciones {analisis['posiciones_picos']}\n")
            txtfile.write(f"Valles detectados: {analisis['num_valles']} en posiciones {analisis['posiciones_valles']}\n")
            txtfile.write(f"Periodicidad: {'S√ç' if analisis['periodicidad_detectada'] else 'NO'}\n\n")
            
            # Cambios significativos
            txtfile.write("CAMBIOS SIGNIFICATIVOS DETECTADOS:\n")
            txtfile.write("-" * 30 + "\n")
            if resultados['cambios_movimiento']:
                for i, cambio in enumerate(resultados['cambios_movimiento']):
                    txtfile.write(f"{i+1}. Posici√≥n {cambio['posicion']}: {cambio['tipo'].upper()}\n")
                    txtfile.write(f"   De {os.path.basename(cambio['imagen_anterior'])}\n")
                    txtfile.write(f"   A {os.path.basename(cambio['imagen_actual'])}\n")
                    txtfile.write(f"   Cambio: {cambio['magnitude_anterior']:.4f} ‚Üí {cambio['magnitude_actual']:.4f} ")
                    txtfile.write(f"({cambio['cambio_relativo']:+.1%})\n\n")
            else:
                txtfile.write("No se detectaron cambios significativos en la secuencia.\n\n")
            
            # Lista de archivos procesados
            txtfile.write("ARCHIVOS PROCESADOS:\n")
            txtfile.write("-" * 30 + "\n")
            for i, archivo in enumerate(resultados['archivos_procesados']):
                txtfile.write(f"{i+1:3d}. {os.path.basename(archivo)}\n")
        
        # Archivo JSON para uso program√°tico
        json_filename = os.path.join(secuencia_dir, f"sequence_analysis_{nombre_secuencia}_{timestamp}.json")
        
        # Funci√≥n auxiliar para convertir tipos NumPy a tipos nativos de Python
        def convert_numpy_types(obj):
            """Convierte tipos de NumPy a tipos nativos de Python para serializaci√≥n JSON."""
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(v) for v in obj]
            else:
                return obj
        
        # Preparar datos JSON serializables
        json_data = {
            'carpeta_path': resultados['carpeta_path'],
            'nombre_secuencia': nombre_secuencia,
            'num_transiciones': resultados['num_transiciones'],
            'analisis_global': convert_numpy_types(resultados['analisis_global']),
            'estadisticas_secuencia': convert_numpy_types(resultados['estadisticas_secuencia'][:50]),  # Limitar para tama√±o
            'cambios_movimiento': convert_numpy_types(resultados['cambios_movimiento']),
            'magnitudes_globales': convert_numpy_types(resultados['magnitudes_globales'][:100]),  # Limitar tama√±o
            'archivos_procesados': [os.path.basename(f) for f in resultados['archivos_procesados']],
            'timestamp': timestamp
        }
        
        with open(json_filename, 'w', encoding='utf-8') as jsonfile:
            json.dump(json_data, jsonfile, indent=2, ensure_ascii=False)
        
        print("üíæ Resultados de an√°lisis de secuencia guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
        print(f"   üìã JSON: {json_filename}")

    def _guardar_resultados_video(self, resultados, nombre_video):
        """Guarda resultados del an√°lisis de video."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Crear directorio espec√≠fico para an√°lisis de video
        video_dir = os.path.join(self.results_dir, "video_analysis")
        os.makedirs(video_dir, exist_ok=True)
        
        # Archivo CSV con estad√≠sticas temporales
        csv_filename = os.path.join(video_dir, f"video_analysis_{nombre_video}_{timestamp}.csv")
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # Encabezados
            writer.writerow(['Tipo', 'M√©trica', 'Valor'])
            
            # Propiedades del video
            props = resultados['video_properties']
            writer.writerow(['Video', 'Resoluci√≥n', f"{props['width']}x{props['height']}"])
            writer.writerow(['Video', 'FPS', f"{props['fps']:.2f}"])
            writer.writerow(['Video', 'Duraci√≥n (s)', f"{props['duration']:.2f}"])
            writer.writerow(['Video', 'Frames Totales', props['total_frames']])
            writer.writerow(['Video', 'Frames Procesados', props['processed_frames']])
            
            # An√°lisis temporal
            temporal = resultados['temporal_analysis']
            writer.writerow(['Temporal', 'Nivel de Actividad', temporal['nivel_actividad']])
            writer.writerow(['Temporal', 'Actividad Promedio', f"{temporal['actividad_promedio']:.4f}"])
            writer.writerow(['Temporal', 'Patr√≥n Dominante', temporal['patron_dominante']])
            writer.writerow(['Temporal', 'Eventos Significativos', temporal['num_eventos']])
            writer.writerow(['Temporal', 'Estabilidad', temporal['estabilidad']])
            writer.writerow(['Temporal', 'Tendencia', temporal['tendencia_movimiento']])
            writer.writerow(['Temporal', 'Variabilidad', f"{temporal['variabilidad_temporal']:.4f}"])
            
            # Periodicidad
            periodicidad = temporal['periodicidad']
            writer.writerow(['Periodicidad', 'Detectada', 'S√≠' if periodicidad['detected'] else 'No'])
            if periodicidad['detected']:
                writer.writerow(['Periodicidad', 'Per√≠odo (frames)', periodicidad['period']])
                writer.writerow(['Periodicidad', 'Confianza', f"{periodicidad['confidence']:.4f}"])
            
            # Estad√≠sticas por frame
            writer.writerow([])  # L√≠nea vac√≠a
            writer.writerow(['Frame', 'Timestamp', 'Magnitud Media', 'Densidad Movimiento', '√Årea Movimiento'])
            
            for stat in resultados['frame_statistics'][:50]:  # Primeros 50 frames
                writer.writerow([
                    stat['frame_number'],
                    f"{stat['timestamp']:.3f}",
                    f"{stat['mean_magnitude']:.4f}",
                    f"{stat['motion_density']:.4f}",
                    stat['movement_area']
                ])
        
        # Archivo TXT con an√°lisis detallado
        txt_filename = os.path.join(video_dir, f"video_analysis_{nombre_video}_{timestamp}.txt")
        with open(txt_filename, 'w', encoding='utf-8') as txtfile:
            txtfile.write(f"AN√ÅLISIS DE VIDEO CON OPTICAL FLOW\n")
            txtfile.write(f"{'='*60}\n")
            txtfile.write(f"Fecha de an√°lisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            txtfile.write(f"Video analizado: {resultados['video_path']}\n\n")
            
            # Propiedades del video
            txtfile.write(f"PROPIEDADES DEL VIDEO:\n")
            txtfile.write(f"{'-'*30}\n")
            props = resultados['video_properties']
            txtfile.write(f"Resoluci√≥n: {props['width']}x{props['height']}\n")
            txtfile.write(f"Frames por segundo: {props['fps']:.2f}\n")
            txtfile.write(f"Duraci√≥n total: {props['duration']:.2f} segundos\n")
            txtfile.write(f"Frames totales: {props['total_frames']}\n")
            txtfile.write(f"Frames procesados: {props['processed_frames']}\n\n")
            
            # An√°lisis temporal
            txtfile.write(f"AN√ÅLISIS TEMPORAL:\n")
            txtfile.write(f"{'-'*30}\n")
            temporal = resultados['temporal_analysis']
            txtfile.write(f"Nivel de actividad: {temporal['nivel_actividad'].upper()}\n")
            txtfile.write(f"Actividad promedio: {temporal['actividad_promedio']:.4f}\n")
            txtfile.write(f"Patr√≥n de movimiento dominante: {temporal['patron_dominante']}\n")
            txtfile.write(f"N√∫mero de eventos significativos: {temporal['num_eventos']}\n")
            txtfile.write(f"Estabilidad del video: {temporal['estabilidad']}\n")
            txtfile.write(f"Tendencia del movimiento: {temporal['tendencia_movimiento']}\n")
            txtfile.write(f"Variabilidad temporal: {temporal['variabilidad_temporal']:.4f}\n")
            txtfile.write(f"Frames con actividad: {temporal['frames_activos']}\n\n")
            
            # Periodicidad
            txtfile.write(f"AN√ÅLISIS DE PERIODICIDAD:\n")
            txtfile.write(f"{'-'*30}\n")
            periodicidad = temporal['periodicidad']
            if periodicidad['detected']:
                txtfile.write(f"Periodicidad detectada: S√ç\n")
                txtfile.write(f"Per√≠odo: {periodicidad['period']} frames\n")
                txtfile.write(f"Confianza: {periodicidad['confidence']:.4f}\n")
            else:
                txtfile.write(f"Periodicidad detectada: NO\n")
            txtfile.write(f"\n")
            
            # Eventos significativos
            eventos = temporal.get('eventos_significativos', [])
            txtfile.write(f"EVENTOS SIGNIFICATIVOS ({len(eventos)}):\n")
            txtfile.write(f"{'-'*30}\n")
            if eventos:
                for i, evento in enumerate(eventos[:10]):  # Mostrar m√°ximo 10 eventos
                    txtfile.write(f"{i+1}. Frame {evento['frame']} "
                                f"(t={evento['timestamp']:.2f}s) - "
                                f"Magnitud: {evento['magnitude']:.4f}\n")
            else:
                txtfile.write("No se detectaron eventos significativos.\n")
            txtfile.write(f"\n")
            
            # Patrones de movimiento
            if resultados.get('movement_patterns'):
                txtfile.write(f"PATRONES DE MOVIMIENTO:\n")
                txtfile.write(f"{'-'*30}\n")
                tipos_movimiento = [p['type'] for p in resultados['movement_patterns']]
                conteo_tipos = {tipo: tipos_movimiento.count(tipo) for tipo in set(tipos_movimiento)}
                
                for tipo, conteo in sorted(conteo_tipos.items(), key=lambda x: x[1], reverse=True):
                    porcentaje = (conteo / len(tipos_movimiento)) * 100
                    txtfile.write(f"{tipo}: {conteo} frames ({porcentaje:.1f}%)\n")
                txtfile.write(f"\n")
            
            # Configuraci√≥n utilizada
            txtfile.write(f"CONFIGURACI√ìN DEL AN√ÅLISIS:\n")
            txtfile.write(f"{'-'*30}\n")
            txtfile.write(f"Algoritmo: Farneback Optical Flow\n")
            config = self.config['optical_flow']
            txtfile.write(f"Escala piramidal: {config['pyr_scale']}\n")
            txtfile.write(f"Niveles: {config['levels']}\n")
            txtfile.write(f"Tama√±o de ventana: {config['winsize']}\n")
            txtfile.write(f"Iteraciones: {config['iterations']}\n")
        
        # Guardar JSON con datos completos para an√°lisis posteriores
        json_filename = os.path.join(video_dir, f"video_analysis_{nombre_video}_{timestamp}.json")
        
        # Preparar datos serializables para JSON
        json_data = {
            'video_path': resultados['video_path'],
            'video_properties': resultados['video_properties'],
            'temporal_analysis': resultados['temporal_analysis'],
            'frame_statistics': resultados['frame_statistics'],
            'movement_patterns': resultados['movement_patterns'][:100] if resultados.get('movement_patterns') else [],  # Limitar para tama√±o
            'motion_history': resultados['motion_history'],
            'analysis_timestamp': timestamp,
            'config_used': self.config['optical_flow']
        }
        
        with open(json_filename, 'w', encoding='utf-8') as jsonfile:
            json.dump(json_data, jsonfile, indent=2, ensure_ascii=False)
        
        print(f"üíæ Resultados de an√°lisis de video guardados:")
        print(f"   üìä CSV: {csv_filename}")
        print(f"   üìù TXT: {txt_filename}")
        print(f"   üìã JSON: {json_filename}")

    def asegurar_directorio_existe(self, ruta_archivo):
        """Asegura que el directorio para un archivo existe antes de guardarlo."""
        directorio = os.path.dirname(ruta_archivo)
        os.makedirs(directorio, exist_ok=True)

# Funci√≥n de utilidad
def analizar_avanzado_imagen(imagen_path, imagen2_path=None, output_dir="./resultados"):
    """
    Funci√≥n de conveniencia para an√°lisis avanzado.
    
    Args:
        imagen_path (str): Ruta a la primera imagen
        imagen2_path (str, optional): Ruta a la segunda imagen
        output_dir (str): Directorio de salida
        
    Returns:
        dict: Resultados del an√°lisis
    """
    analyzer = AdvancedAnalyzer(output_dir)
    resultado = analyzer.analisis_completo_avanzado(imagen_path, imagen2_path)
    if resultado:
        analyzer.guardar_resultados('csv')
        analyzer.generar_reporte_avanzado()
    return resultado