#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
M√≥dulo HOG y KAZE para An√°lisis de Tr√°fico Vehicular
===================================================

Implementaci√≥n de descriptores HOG (Histogram of Oriented Gradients) y 
KAZE para identificaci√≥n de objetos en im√°genes de tr√°fico vehicular.

FUNDAMENTOS TE√ìRICOS
====================

HOG (Histogram of Oriented Gradients)
--------------------------------------
HOG es un descriptor de caracter√≠sticas basado en la distribuci√≥n de gradientes
de intensidad locales en una imagen.

**Base Matem√°tica:**

1. C√°lculo de Gradientes:
   - Gradiente horizontal: Gx(x,y) = I(x+1,y) - I(x-1,y)
   - Gradiente vertical: Gy(x,y) = I(x,y+1) - I(x,y-1)
   - Magnitud: |G(x,y)| = ‚àö(Gx¬≤ + Gy¬≤)
   - Orientaci√≥n: Œ∏(x,y) = arctan(Gy/Gx)

2. Agrupaci√≥n en Celdas:
   - La imagen se divide en celdas de tama√±o fijo (t√≠picamente 8√ó8 p√≠xeles)
   - Para cada celda se calcula un histograma de orientaciones
   - El histograma t√≠picamente usa 9 bins cubriendo 0¬∞-180¬∞ (sin signo)

3. Normalizaci√≥n por Bloques:
   - Los bloques son grupos de celdas (t√≠picamente 2√ó2 celdas)
   - Normalizaci√≥n L2-Hys: v' = v / ‚àö(||v||‚ÇÇ¬≤ + Œµ¬≤)
     donde v es el vector del bloque y Œµ es una constante peque√±a
   - Esto proporciona invarianza a cambios de iluminaci√≥n

4. Vector de Caracter√≠sticas Final:
   - Concatenaci√≥n de todos los histogramas normalizados
   - Dimensi√≥n: n_blocks √ó cells_per_block¬≤ √ó orientations

**Ventajas:**
- Robusto ante cambios de iluminaci√≥n
- Captura informaci√≥n de forma local
- Invariante a peque√±as deformaciones
- Alta tasa de detecci√≥n para objetos r√≠gidos

KAZE
----
KAZE es un detector y descriptor de caracter√≠sticas que utiliza difusi√≥n
no lineal en lugar de suavizado gaussiano.

**Base Matem√°tica:**

1. Ecuaci√≥n de Difusi√≥n No Lineal:
   ‚àÇL/‚àÇt = div(c(x,y,t) ¬∑ ‚àáL)
   
   donde:
   - L es el espacio de escala no lineal
   - c(x,y,t) es la funci√≥n de conductividad
   - div es el operador divergencia
   - ‚àáL es el gradiente de la imagen

2. Funci√≥n de Conductividad (Perona-Malik):
   c(x,y,t) = g(|‚àáLœÉ(x,y,t)|)
   
   Tipo PM_G2: g(x) = 1 / (1 + (|‚àáLœÉ|/K)¬≤)
   donde K es un par√°metro de contraste

3. Construcci√≥n del Espacio de Escala:
   - Se resuelve la ecuaci√≥n de difusi√≥n en m√∫ltiples octavas
   - Cada octava duplica el tiempo de difusi√≥n
   - Preserva mejor los bordes que el suavizado gaussiano

4. Detecci√≥n de Puntos Clave:
   - Se buscan extremos en el determinante del Hessiano:
     Det(H) = Lxx¬∑Lyy - Lxy¬≤
   - Se refinan las posiciones usando interpolaci√≥n cuadr√°tica

**Ventajas:**
- Preserva bordes durante el suavizado
- Mayor precisi√≥n en localizaci√≥n de caracter√≠sticas
- Robusto ante cambios de escala y rotaci√≥n
- Mejor para im√°genes con detalles finos

APLICACIONES EN TR√ÅFICO VEHICULAR
==================================

HOG es especialmente efectivo para:
- Detecci√≥n de veh√≠culos y peatones (forma caracter√≠stica)
- An√°lisis de se√±ales de tr√°fico (contornos geom√©tricos)
- Clasificaci√≥n de objetos basada en gradientes
- Identificaci√≥n de patrones estructurados

KAZE es √∫til para:
- Detecci√≥n de puntos clave robustos en se√±ales
- An√°lisis de texturas locales en superficies vehiculares
- Matching de caracter√≠sticas para seguimiento
- Reconocimiento de matr√≠culas y elementos texturizados
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
from skimage.feature import hog, local_binary_pattern
from skimage import exposure, img_as_ubyte
import seaborn as sns

class HOGKAZEAnalyzer:
    """Analizador HOG y KAZE para tr√°fico vehicular."""
    
    def __init__(self, output_dir="./resultados"):
        """
        Inicializar el analizador HOG-KAZE.
        
        Args:
            output_dir (str): Directorio de salida para resultados
        """
        self.output_dir = output_dir
        self.results_dir = os.path.join(output_dir, "hog_kaze_analysis")
        os.makedirs(self.results_dir, exist_ok=True)
        self.current_results = []
        
        # Configuraci√≥n HOG para tr√°fico vehicular
        self.hog_config = {
            'orientations': 9,
            'pixels_per_cell': (8, 8),
            'cells_per_block': (2, 2),
            'block_norm': 'L2-Hys',
            'transform_sqrt': True,
            'feature_vector': True
        }
        
        # Configuraci√≥n KAZE
        self.kaze_config = {
            'threshold': 0.003,
            'nOctaves': 4,
            'nOctaveLayers': 4,
            'diffusivity': cv2.KAZE_DIFF_PM_G2
        }
    
    def extraer_caracteristicas_hog(self, imagen, visualizar=True, mostrar_descriptores=True, guardar_resultados=False, nombre_imagen="imagen_hog"):
        """
        Extrae caracter√≠sticas HOG (Histogram of Oriented Gradients) de la imagen.
        
        PROCESO DEL ALGORITMO:
        ======================
        
        1. **Preprocesamiento:**
           - Conversi√≥n a escala de grises para simplificar el c√°lculo
           - Ecualizaci√≥n de histograma para normalizar la iluminaci√≥n
           - F√≥rmula de ecualizaci√≥n: h'(i) = ‚åä(L-1) ¬∑ CDF(i)‚åã
             donde CDF es la funci√≥n de distribuci√≥n acumulativa
        
        2. **C√°lculo de Gradientes:**
           - Se aplica el operador Sobel o diferencias centradas
           - Gx = [-1, 0, 1] convoluci√≥n horizontal
           - Gy = [-1, 0, 1]·µÄ convoluci√≥n vertical
           - Magnitud y orientaci√≥n en cada p√≠xel
        
        3. **Construcci√≥n de Histogramas:**
           - Divisi√≥n en celdas de 8√ó8 p√≠xeles (configurable)
           - Cada celda genera un histograma de 9 orientaciones
           - Votaci√≥n ponderada por magnitud del gradiente
           - Interpolaci√≥n bilineal entre bins adyacentes
        
        4. **Normalizaci√≥n por Bloques:**
           - Bloques de 2√ó2 celdas con solapamiento
           - Normalizaci√≥n L2-Hys con umbral en 0.2:
             * v_norm = v / ‚àö(||v||‚ÇÇ¬≤ + Œµ¬≤)
             * v_clipped = min(v_norm, 0.2)
             * v_final = v_clipped / ‚àö(||v_clipped||‚ÇÇ¬≤ + Œµ¬≤)
           - Proporciona robustez ante variaciones de iluminaci√≥n
        
        5. **An√°lisis Estad√≠stico:**
           - Media y desviaci√≥n est√°ndar del vector HOG
           - Energ√≠a: E = Œ£(features¬≤) - medida de intensidad total
           - Entrop√≠a: H = -Œ£(p¬∑log‚ÇÇ(p)) - medida de informaci√≥n
           - Sparsity: porcentaje de caracter√≠sticas cercanas a cero
        
        6. **An√°lisis Direccional:**
           - Separaci√≥n de caracter√≠sticas por orientaci√≥n
           - Identificaci√≥n de orientaci√≥n dominante
           - √çndice de estructura: max(E_orient) / mean(E_orient)
           - Alto √≠ndice ‚Üí objeto con direcci√≥n preferente (ej: veh√≠culo)
        
        M√âTRICAS EXTRA√çDAS:
        ===================
        - num_features: Dimensi√≥n del vector HOG
        - hog_mean, hog_std: Estad√≠sticas b√°sicas
        - hog_energy: Suma de cuadrados de caracter√≠sticas
        - hog_entropy: Medida de informaci√≥n contenida
        - dominant_orientation: Direcci√≥n con mayor energ√≠a
        - structure_index: Medida de organizaci√≥n direccional
        - orientation_entropy: Uniformidad de distribuci√≥n direccional
        
        Args:
            imagen (np.ndarray): Imagen de entrada (puede ser BGR o escala de grises)
            visualizar (bool): Si True, genera visualizaci√≥n del mapa HOG
            mostrar_descriptores (bool): Si True, imprime estad√≠sticas en consola
            guardar_resultados (bool): Si True, guarda archivos CSV y TXT
            nombre_imagen (str): Nombre base para archivos de salida
            
        Returns:
            dict: Diccionario con caracter√≠sticas HOG y metadatos:
                - Estad√≠sticas globales (mean, std, energy, entropy)
                - Estad√≠sticas por orientaci√≥n
                - Im√°genes procesadas (gray_image, normalized_image, hog_image)
                - Vector de caracter√≠sticas crudas (hog_features_raw)
                
        Example:
            >>> analyzer = HOGKAZEAnalyzer()
            >>> imagen = cv2.imread('vehiculo.jpg')
            >>> resultados = analyzer.extraer_caracteristicas_hog(imagen)
            >>> print(f"Caracter√≠sticas extra√≠das: {resultados['num_features']}")
            >>> print(f"Orientaci√≥n dominante: {resultados['dominant_orientation']}¬∞")
        """
        print("üîç Extrayendo caracter√≠sticas HOG...")
        print("="*60)
        
        # Convertir a escala de grises
        if len(imagen.shape) == 3:
            imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
        else:
            imagen_gris = imagen.copy()
        
        # Normalizar imagen
        imagen_norm = exposure.equalize_hist(imagen_gris)
        
        # Extraer HOG con visualizaci√≥n
        hog_features, hog_image = hog(imagen_norm,
                                    orientations=self.hog_config['orientations'],
                                    pixels_per_cell=self.hog_config['pixels_per_cell'],
                                    cells_per_block=self.hog_config['cells_per_block'],
                                    block_norm=self.hog_config['block_norm'],
                                    transform_sqrt=self.hog_config['transform_sqrt'],
                                    visualize=True,
                                    feature_vector=self.hog_config['feature_vector'])
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            print(f"üìä AN√ÅLISIS DE CARACTER√çSTICAS HOG - {nombre_imagen.upper()}")
            print("="*60)
            print(f"üìê Dimensiones de la imagen: {imagen_gris.shape}")
            print(f"üéØ N√∫mero de caracter√≠sticas HOG extra√≠das: {len(hog_features)}")
            print(f"üìä Forma del vector de caracter√≠sticas: {hog_features.shape}")
            print("\nüìà Estad√≠sticas de las caracter√≠sticas:")
            print(f"   ‚Ä¢ Valor m√≠nimo: {np.min(hog_features):.8f}")
            print(f"   ‚Ä¢ Valor m√°ximo: {np.max(hog_features):.8f}")
            print(f"   ‚Ä¢ Promedio: {np.mean(hog_features):.8f}")
            print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: {np.std(hog_features):.8f}")
            print(f"   ‚Ä¢ Energ√≠a total: {np.sum(hog_features**2):.6f}")
            
            print(f"\nüîç Primeras 20 caracter√≠sticas HOG:")
            for i in range(min(20, len(hog_features))):
                print(f"   Caracter√≠stica {i+1:3d}: {hog_features[i]:15.8f}")
            
            if len(hog_features) > 20:
                print(f"\nüîç √öltimas 10 caracter√≠sticas HOG:")
                start_idx = max(0, len(hog_features) - 10)
                for i in range(start_idx, len(hog_features)):
                    print(f"   Caracter√≠stica {i+1:3d}: {hog_features[i]:15.8f}")
            
            print(f"\nüíæ Para ver todas las {len(hog_features)} caracter√≠sticas, active guardar_resultados=True")
            print("="*60)
        
        # An√°lisis estad√≠stico de caracter√≠sticas HOG
        hog_stats = {
            'num_features': len(hog_features),
            'hog_mean': np.mean(hog_features),
            'hog_std': np.std(hog_features),
            'hog_min': np.min(hog_features),
            'hog_max': np.max(hog_features),
            'hog_energy': np.sum(hog_features ** 2),
            'hog_entropy': self._calculate_entropy(hog_features),
            'hog_sparsity': np.sum(hog_features == 0) / len(hog_features)
        }
        
        # An√°lisis direccional de gradientes
        orientations = self.hog_config['orientations']
        
        # Dividir caracter√≠sticas por orientaci√≥n
        features_per_cell = orientations * self.hog_config['cells_per_block'][0] * self.hog_config['cells_per_block'][1]
        orientation_histograms = []
        
        for i in range(0, len(hog_features), features_per_cell):
            block_features = hog_features[i:i+features_per_cell]
            if len(block_features) == features_per_cell:
                # Promedio por orientaci√≥n en el bloque
                for j in range(orientations):
                    orient_features = block_features[j::orientations]
                    if j >= len(orientation_histograms):
                        orientation_histograms.append([])
                    orientation_histograms[j].extend(orient_features)
        
        # Estad√≠sticas por orientaci√≥n
        orientation_stats = {}
        for i, orient_hist in enumerate(orientation_histograms):
            if orient_hist:
                orientation_stats[f'orientation_{i}_mean'] = np.mean(orient_hist)
                orientation_stats[f'orientation_{i}_std'] = np.std(orient_hist)
                orientation_stats[f'orientation_{i}_energy'] = np.sum(np.array(orient_hist) ** 2)
        
        # An√°lisis de dominancia direccional
        orientation_energies = [orientation_stats.get(f'orientation_{i}_energy', 0) 
                               for i in range(orientations)]
        dominant_orientation = np.argmax(orientation_energies)
        orientation_entropy = self._calculate_entropy(orientation_energies)
        
        # M√©tricas espec√≠ficas para veh√≠culos
        # √çndice de estructura (alta energ√≠a en orientaciones espec√≠ficas)
        structure_index = np.max(orientation_energies) / (np.mean(orientation_energies) + 1e-10)
        
        # √çndice de textura direccional
        directional_variance = np.var(orientation_energies)
        
        resultados = {
            **hog_stats,
            **orientation_stats,
            'dominant_orientation': dominant_orientation,
            'orientation_entropy': orientation_entropy,
            'structure_index': structure_index,
            'directional_variance': directional_variance,
            'hog_image': hog_image,
            'hog_features_raw': hog_features,
            'gray_image': imagen_gris,
            'normalized_image': imagen_norm,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_hog(resultados, nombre_imagen)
        
        if visualizar:
            self._visualizar_hog(resultados)
        
        return resultados
    
    def extraer_caracteristicas_kaze(self, imagen, visualizar=True, mostrar_descriptores=True, guardar_resultados=False, nombre_imagen="imagen_kaze", usar_config_default=False):
        """
        Extrae caracter√≠sticas KAZE (Accelerated KAZE) de la imagen usando difusi√≥n no lineal.
        
        PROCESO DEL ALGORITMO:
        ======================
        
        1. **Construcci√≥n del Espacio de Escala No Lineal:**
           - Se resuelve la ecuaci√≥n de difusi√≥n: ‚àÇL/‚àÇt = div(c(x,y,t)¬∑‚àáL)
           - Difusividad Perona-Malik G2: c = 1/(1 + (|‚àáL|/K)¬≤)
           - Ventaja: preserva bordes mientras suaviza regiones uniformes
           - Se construyen 4 octavas con 4 capas cada una (configurable)
        
        2. **Detecci√≥n de Puntos Clave:**
           - B√∫squeda de extremos en el determinante del Hessiano:
             Det(H) = Lxx¬∑Lyy - Lxy¬≤
           - Umbralizaci√≥n: solo se mantienen respuestas > threshold
           - Refinamiento sub-p√≠xel usando interpolaci√≥n cuadr√°tica
           - Eliminaci√≥n de puntos con bajo contraste o en bordes
        
        3. **Asignaci√≥n de Orientaci√≥n:**
           - Para cada punto clave se calcula un histograma de gradientes
           - Radio de b√∫squeda proporcional a la escala: r = 6¬∑œÉ
           - Gradientes ponderados por funci√≥n gaussiana circular
           - Orientaci√≥n principal = pico del histograma suavizado
        
        4. **Construcci√≥n de Descriptores:**
           - Regi√≥n de 20œÉ √ó 20œÉ alrededor del punto clave
           - Rotaci√≥n seg√∫n orientaci√≥n principal (invarianza rotacional)
           - Subdivisi√≥n en 4√ó4 = 16 subregiones
           - Para cada subregi√≥n: descriptor basado en gradientes
           - Vector final de 64 dimensiones (KAZE est√°ndar)
        
        5. **An√°lisis de Distribuci√≥n Espacial:**
           - C√°lculo del centroide: (xÃÑ,»≥) = (Œ£xi/n, Œ£yi/n)
           - Dispersi√≥n espacial: œÉ¬≤ = Œ£(xi-xÃÑ)¬≤ + Œ£(yi-»≥)¬≤
           - Cobertura de imagen: porcentaje de √°rea con puntos clave
           - Clustering: agrupaci√≥n de puntos cercanos
        
        6. **An√°lisis Multi-Escala:**
           - Distribuci√≥n de escalas (tama√±os) de puntos clave
           - Consistencia multi-escala: correlaci√≥n entre escalas
           - Respuestas fuertes en m√∫ltiples escalas ‚Üí caracter√≠sticas estables
        
        M√âTRICAS EXTRA√çDAS:
        ===================
        
        **Puntos Clave:**
        - num_keypoints: Cantidad total detectada
        - mean_response: Respuesta promedio del detector
        - scale_mean/std: Estad√≠sticas de escalas
        - centroid_x/y: Centro de masa de los puntos
        - spatial_spread: Dispersi√≥n espacial
        
        **Descriptores:**
        - descriptor_mean/std: Estad√≠sticas del vector
        - descriptor_diversity: Medida de variabilidad entre descriptores
        - descriptor_sparsity: Porcentaje de valores cercanos a cero
        
        **Distribuci√≥n Espacial:**
        - coverage_percentage: Porcentaje de imagen cubierta
        - density_per_region: Densidad local de puntos
        - uniformity_score: Uniformidad de distribuci√≥n
        
        CONFIGURACI√ìN:
        ==============
        - threshold: 0.003 (sensibilidad de detecci√≥n)
        - nOctaves: 4 (n√∫mero de escalas principales)
        - nOctaveLayers: 4 (subdivisiones por octava)
        - diffusivity: PM_G2 (funci√≥n de difusi√≥n Perona-Malik)
        
        Args:
            imagen (np.ndarray): Imagen de entrada (puede ser BGR o escala de grises)
            visualizar (bool): Si True, genera visualizaci√≥n de puntos clave
            mostrar_descriptores (bool): Si True, imprime estad√≠sticas detalladas
            guardar_resultados (bool): Si True, guarda archivos CSV y TXT
            nombre_imagen (str): Nombre base para archivos de salida
            usar_config_default (bool): Si True, usa configuraci√≥n b√°sica sin par√°metros avanzados
            
        Returns:
            dict: Diccionario con caracter√≠sticas KAZE:
                - Estad√≠sticas de puntos clave (cantidad, respuestas, escalas)
                - Estad√≠sticas de descriptores (mean, std, diversity)
                - An√°lisis espacial (centroide, dispersi√≥n, cobertura)
                - Datos crudos (keypoints, descriptors, gray_image)
                
        Example:
            >>> analyzer = HOGKAZEAnalyzer()
            >>> imagen = cv2.imread('se√±al_transito.jpg')
            >>> resultados = analyzer.extraer_caracteristicas_kaze(imagen)
            >>> print(f"Puntos clave detectados: {resultados['num_keypoints']}")
            >>> print(f"Cobertura espacial: {resultados['coverage_percentage']:.1f}%")
        
        Note:
            KAZE es especialmente efectivo para im√°genes con bordes n√≠tidos y detalles finos,
            como se√±ales de tr√°fico, matr√≠culas y texturas vehiculares.
        """
        print("üîç Extrayendo caracter√≠sticas KAZE...")
        print("="*60)
        
        # Convertir a escala de grises
        if len(imagen.shape) == 3:
            imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
        else:
            imagen_gris = imagen.copy()
        
        # Crear detector KAZE
        if usar_config_default:
            # Configuraci√≥n por defecto (como la profesora)
            kaze = cv2.KAZE_create()
            print("üîß Usando configuraci√≥n KAZE por defecto (como la profesora)")
        else:
            # Configuraci√≥n avanzada personalizada
            kaze = cv2.KAZE_create(
                extended=False,
                upright=False,
                threshold=self.kaze_config['threshold'],
                nOctaves=self.kaze_config['nOctaves'],
                nOctaveLayers=self.kaze_config['nOctaveLayers'],
                diffusivity=self.kaze_config['diffusivity']
            )
            print("üîß Usando configuraci√≥n KAZE avanzada")
        
        # Detectar puntos clave y calcular descriptores
        keypoints, descriptors = kaze.detectAndCompute(imagen_gris, None)
        
        # Mostrar informaci√≥n detallada en consola
        if mostrar_descriptores:
            print(f"üîë AN√ÅLISIS DE CARACTER√çSTICAS KAZE - {nombre_imagen.upper()}")
            print("="*60)
            print(f"üìê Dimensiones de la imagen: {imagen_gris.shape}")
            print(f"üéØ N√∫mero de puntos clave detectados: {len(keypoints)}")
            
            if descriptors is not None:
                print(f"üìä Forma de la matriz de descriptores: {descriptors.shape}")
                print(f"üî¢ Dimensi√≥n de cada descriptor: {descriptors.shape[1]}")
                print(f"üìà Total de descriptores: {descriptors.shape[0]}")
                
                print("\nüìä Estad√≠sticas de los descriptores:")
                print(f"   ‚Ä¢ Valor m√≠nimo: {np.min(descriptors):.8f}")
                print(f"   ‚Ä¢ Valor m√°ximo: {np.max(descriptors):.8f}")
                print(f"   ‚Ä¢ Promedio: {np.mean(descriptors):.8f}")
                print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: {np.std(descriptors):.8f}")
                
                print(f"\nüîç Informaci√≥n detallada de los primeros 5 puntos clave:")
                for i in range(min(5, len(keypoints))):
                    kp = keypoints[i]
                    print(f"   üìç Punto clave {i+1}:")
                    print(f"      ‚Ä¢ Posici√≥n (x,y): ({kp.pt[0]:.2f}, {kp.pt[1]:.2f})")
                    print(f"      ‚Ä¢ Tama√±o: {kp.size:.2f}")
                    print(f"      ‚Ä¢ √Ångulo: {kp.angle:.2f}¬∞")
                    print(f"      ‚Ä¢ Respuesta: {kp.response:.8f}")
                    print(f"      ‚Ä¢ Descriptor (primeros 10 valores): {descriptors[i][:10]}")
                
                if len(keypoints) > 0:
                    print(f"\nüéØ Descriptor completo del primer punto clave:")
                    descriptor_str = ', '.join([f"{val:.8f}" for val in descriptors[0]])
                    print(f"   Descriptor 1: [{descriptor_str}]")
                    
                    if len(keypoints) > 1:
                        print(f"\nüéØ Descriptor completo del √∫ltimo punto clave:")
                        descriptor_str = ', '.join([f"{val:.8f}" for val in descriptors[-1]])
                        print(f"   Descriptor {len(keypoints)}: [{descriptor_str}]")
                
                print(f"\nüíæ Para ver todos los {len(keypoints)} descriptores completos, active guardar_resultados=True")
            else:
                print("‚ùå No se pudieron calcular descriptores")
            
            print("="*60)
        
        # An√°lisis de puntos clave
        num_keypoints = len(keypoints)
        
        if num_keypoints > 0:
            # Estad√≠sticas de localizaci√≥n de puntos clave
            kp_x = [kp.pt[0] for kp in keypoints]
            kp_y = [kp.pt[1] for kp in keypoints]
            kp_size = [kp.size for kp in keypoints]
            kp_angle = [kp.angle for kp in keypoints]
            kp_response = [kp.response for kp in keypoints]
            
            # Estad√≠sticas espaciales
            keypoint_stats = {
                'num_keypoints': num_keypoints,
                'kp_mean_x': np.mean(kp_x),
                'kp_std_x': np.std(kp_x),
                'kp_mean_y': np.mean(kp_y),
                'kp_std_y': np.std(kp_y),
                'kp_mean_size': np.mean(kp_size),
                'kp_std_size': np.std(kp_size),
                'kp_mean_response': np.mean(kp_response),
                'kp_std_response': np.std(kp_response),
                'kp_density': num_keypoints / (imagen_gris.shape[0] * imagen_gris.shape[1])
            }
            
            # An√°lisis de √°ngulos
            valid_angles = [angle for angle in kp_angle if angle >= 0]
            if valid_angles:
                keypoint_stats.update({
                    'kp_mean_angle': np.mean(valid_angles),
                    'kp_std_angle': np.std(valid_angles),
                    'kp_angle_entropy': self._calculate_entropy(np.histogram(valid_angles, bins=36)[0])
                })
            
            # An√°lisis de descriptores
            if descriptors is not None:
                descriptor_stats = {
                    'descriptor_length': descriptors.shape[1],
                    'descriptor_mean': np.mean(descriptors),
                    'descriptor_std': np.std(descriptors),
                    'descriptor_sparsity': np.sum(descriptors == 0) / descriptors.size,
                    'descriptor_energy': np.sum(descriptors ** 2),
                    'descriptor_entropy': self._calculate_entropy(descriptors.flatten())
                }
                
                # An√°lisis de diversidad de descriptores
                descriptor_diversity = self._calculate_descriptor_diversity(descriptors)
                descriptor_stats['descriptor_diversity'] = descriptor_diversity
            else:
                descriptor_stats = {
                    'descriptor_length': 0,
                    'descriptor_mean': 0,
                    'descriptor_std': 0,
                    'descriptor_sparsity': 0,
                    'descriptor_energy': 0,
                    'descriptor_entropy': 0,
                    'descriptor_diversity': 0
                }
            
            # An√°lisis espacial avanzado
            spatial_stats = self._analisis_espacial_keypoints(kp_x, kp_y, imagen_gris.shape)
            
        else:
            # No se detectaron puntos clave
            keypoint_stats = {
                'num_keypoints': 0,
                'kp_mean_x': 0, 'kp_std_x': 0,
                'kp_mean_y': 0, 'kp_std_y': 0,
                'kp_mean_size': 0, 'kp_std_size': 0,
                'kp_mean_response': 0, 'kp_std_response': 0,
                'kp_density': 0,
                'kp_mean_angle': 0, 'kp_std_angle': 0,
                'kp_angle_entropy': 0
            }
            
            descriptor_stats = {
                'descriptor_length': 0, 'descriptor_mean': 0,
                'descriptor_std': 0, 'descriptor_sparsity': 0,
                'descriptor_energy': 0, 'descriptor_entropy': 0,
                'descriptor_diversity': 0
            }
            
            spatial_stats = {
                'spatial_uniformity': 0,
                'spatial_clustering': 0,
                'edge_keypoint_ratio': 0
            }
        
        resultados = {
            **keypoint_stats,
            **descriptor_stats,
            **spatial_stats,
            'keypoints': keypoints,
            'descriptors': descriptors,
            'gray_image': imagen_gris,
            'nombre_imagen': nombre_imagen
        }
        
        # Guardar resultados si se solicita
        if guardar_resultados:
            self._guardar_resultados_kaze(resultados, nombre_imagen)
        
        if visualizar:
            self._visualizar_kaze(resultados)
        
        return resultados
    
    def analisis_combinado_hog_kaze(self, imagen_path, nombre_imagen=None):
        """
        Realiza an√°lisis combinado HOG + KAZE.
        
        Args:
            imagen_path (str): Ruta a la imagen
            nombre_imagen (str): Nombre personalizado
            
        Returns:
            dict: Resultados combinados
        """
        try:
            # Cargar imagen
            imagen = cv2.imread(imagen_path)
            if imagen is None:
                raise ValueError(f"No se pudo cargar la imagen: {imagen_path}")
            
            if nombre_imagen is None:
                nombre_imagen = os.path.basename(imagen_path)
            
            print(f"üîÑ An√°lisis HOG-KAZE para: {nombre_imagen}")
            
            # An√°lisis HOG
            resultados_hog = self.extraer_caracteristicas_hog(imagen, visualizar=False)
            
            # An√°lisis KAZE
            resultados_kaze = self.extraer_caracteristicas_kaze(imagen, visualizar=False)
            
            # An√°lisis adicional: LBP (Local Binary Patterns)
            lbp_stats = self._extraer_lbp(imagen)
            
            # Combinar resultados
            resultado_completo = {
                'Imagen': nombre_imagen,
                'Ruta': imagen_path,
                'Dimensiones': imagen.shape,
                'Fecha_Analisis': datetime.now().isoformat(),
                **{f'hog_{k}': v for k, v in resultados_hog.items() 
                   if not isinstance(v, np.ndarray)},
                **{f'kaze_{k}': v for k, v in resultados_kaze.items() 
                   if not isinstance(v, (list, np.ndarray))},
                **{f'lbp_{k}': v for k, v in lbp_stats.items()}
            }
            
            self.current_results.append(resultado_completo)
            
            print(f"‚úÖ An√°lisis HOG-KAZE completado para: {nombre_imagen}")
            return resultado_completo
            
        except Exception as e:
            print(f"‚ùå Error al procesar {imagen_path}: {str(e)}")
            return None
    
    def _extraer_lbp(self, imagen):
        """Extrae caracter√≠sticas Local Binary Pattern."""
        if len(imagen.shape) == 3:
            imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
        else:
            imagen_gris = imagen.copy()
        
        # Calcular LBP
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(imagen_gris, n_points, radius, method='uniform')
        
        # Histograma LBP
        hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2, 
                             range=(0, n_points + 2), density=True)
        
        return {
            'lbp_entropy': self._calculate_entropy(hist),
            'lbp_uniformity': np.sum(hist ** 2),
            'lbp_variance': np.var(hist),
            'lbp_mean': np.mean(lbp),
            'lbp_std': np.std(lbp)
        }
    
    def _calculate_entropy(self, data):
        """Calcula la entrop√≠a de los datos."""
        if isinstance(data, np.ndarray):
            data = data.flatten()
        
        # Crear histograma
        hist, _ = np.histogram(data, bins=50, density=True)
        hist = hist[hist > 0]  # Remover bins vac√≠os
        
        if len(hist) == 0:
            return 0
        
        return -np.sum(hist * np.log2(hist))
    
    def _calculate_descriptor_diversity(self, descriptors):
        """Calcula diversidad entre descriptores."""
        if descriptors is None or len(descriptors) < 2:
            return 0
        
        # Calcular distancias entre pares de descriptores
        from scipy.spatial.distance import pdist
        distances = pdist(descriptors, metric='euclidean')
        return np.mean(distances)
    
    def _analisis_espacial_keypoints(self, kp_x, kp_y, image_shape):
        """Analiza la distribuci√≥n espacial de puntos clave."""
        if not kp_x or not kp_y:
            return {
                'spatial_uniformity': 0,
                'spatial_clustering': 0,
                'edge_keypoint_ratio': 0
            }
        
        h, w = image_shape[:2]
        
        # Uniformidad espacial (coeficiente de variaci√≥n de distancias)
        points = np.column_stack((kp_x, kp_y))
        if len(points) > 1:
            from scipy.spatial.distance import pdist
            distances = pdist(points)
            spatial_uniformity = np.std(distances) / (np.mean(distances) + 1e-10)
        else:
            spatial_uniformity = 0
        
        # Clustering espacial (usando densidad local)
        edge_margin = min(w, h) * 0.1
        edge_points = sum(1 for x, y in zip(kp_x, kp_y) 
                         if x < edge_margin or x > w - edge_margin or 
                            y < edge_margin or y > h - edge_margin)
        edge_keypoint_ratio = edge_points / len(kp_x) if kp_x else 0
        
        return {
            'spatial_uniformity': spatial_uniformity,
            'spatial_clustering': 1.0 / (spatial_uniformity + 1),  # Inverso de uniformidad
            'edge_keypoint_ratio': edge_keypoint_ratio
        }
    
    def _visualizar_hog(self, resultados):
        """Visualiza los resultados HOG."""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        # Imagen original
        axes[0].imshow(resultados['gray_image'], cmap='gray')
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')
        
        # Imagen normalizada
        axes[1].imshow(resultados['normalized_image'], cmap='gray')
        axes[1].set_title('Imagen Normalizada')
        axes[1].axis('off')
        
        # Visualizaci√≥n HOG
        hog_image_rescaled = exposure.rescale_intensity(resultados['hog_image'], in_range=(0, 10))
        axes[2].imshow(hog_image_rescaled, cmap='hot')
        axes[2].set_title(f'HOG Features ({resultados["num_features"]} caracter√≠sticas)')
        axes[2].axis('off')
        
        plt.tight_layout()
        archivo_viz = os.path.join(self.results_dir, f'hog_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png')
        plt.savefig(archivo_viz, dpi=300, bbox_inches='tight')
        plt.show()
        
        # Gr√°fico de estad√≠sticas direccionales
        orientations = self.hog_config['orientations']
        orientation_energies = [resultados.get(f'orientation_{i}_energy', 0) for i in range(orientations)]
        
        if any(orientation_energies):
            fig, ax = plt.subplots(1, 1, figsize=(10, 6))
            angles = np.linspace(0, 180, orientations, endpoint=False)
            ax.bar(angles, orientation_energies, width=180/orientations*0.8)
            ax.set_xlabel('Orientaci√≥n (grados)')
            ax.set_ylabel('Energ√≠a')
            ax.set_title('Distribuci√≥n Direccional HOG')
            ax.grid(True, alpha=0.3)
            
            archivo_direccional = os.path.join(self.results_dir, f'hog_directions_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png')
            plt.savefig(archivo_direccional, dpi=300, bbox_inches='tight')
            plt.show()
    
    def _visualizar_kaze(self, resultados):
        """Visualiza los resultados KAZE."""
        fig, axes = plt.subplots(1, 2, figsize=(15, 8))
        
        # Imagen original
        axes[0].imshow(resultados['gray_image'], cmap='gray')
        axes[0].set_title('Imagen Original')
        axes[0].axis('off')
        
        # Puntos clave KAZE - Crear imagen en color para mostrar puntos amarillos
        if len(resultados['gray_image'].shape) == 2:
            # Convertir imagen gris a color (RGB) para poder mostrar puntos amarillos
            img_kp = cv2.cvtColor(resultados['gray_image'], cv2.COLOR_GRAY2RGB)
        else:
            img_kp = resultados['gray_image'].copy()
        
        if resultados['keypoints']:
            # Dibujar puntos clave con color amarillo (255, 255, 0) y sin flags para puntos m√°s peque√±os
            img_kp = cv2.drawKeypoints(img_kp, resultados['keypoints'], None, 
                                     color=(255, 255, 0), flags=0)
        
        axes[1].imshow(img_kp)
        axes[1].set_title(f'Puntos Clave KAZE ({resultados["num_keypoints"]})')
        axes[1].axis('off')
        
        plt.tight_layout()
        archivo_viz = os.path.join(self.results_dir, f'kaze_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png')
        plt.savefig(archivo_viz, dpi=300, bbox_inches='tight')
        plt.show()
    
    def guardar_resultados(self, formato='csv'):
        """Guarda los resultados del an√°lisis."""
        if not self.current_results:
            print("‚ùå No hay resultados para guardar.")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if formato.lower() == 'csv':
            df = pd.DataFrame(self.current_results)
            archivo_csv = os.path.join(self.results_dir, f'hog_kaze_analysis_{timestamp}.csv')
            df.to_csv(archivo_csv, index=False)
            print(f"üíæ Resultados CSV guardados: {archivo_csv}")
        
        elif formato.lower() == 'json':
            import json
            archivo_json = os.path.join(self.results_dir, f'hog_kaze_analysis_{timestamp}.json')
            with open(archivo_json, 'w', encoding='utf-8') as f:
                json.dump(self.current_results, f, indent=2, ensure_ascii=False, default=str)
            print(f"üíæ Resultados JSON guardados: {archivo_json}")
    
    def generar_reporte_hog_kaze(self):
        """Genera reporte del an√°lisis HOG-KAZE."""
        if not self.current_results:
            print("‚ùå No hay resultados para el reporte.")
            return
        
        print("\nüìã REPORTE AN√ÅLISIS HOG + KAZE")
        print("=" * 40)
        print(f"üìä Im√°genes analizadas: {len(self.current_results)}")
        
        # Estad√≠sticas HOG
        hog_features = [r.get('hog_num_features', 0) for r in self.current_results]
        hog_energies = [r.get('hog_hog_energy', 0) for r in self.current_results]
        
        print(f"\nüéØ ESTAD√çSTICAS HOG:")
        print(f"   Caracter√≠sticas promedio: {np.mean(hog_features):.0f}")
        print(f"   Energ√≠a promedio: {np.mean(hog_energies):.2f}")
        
        # Estad√≠sticas KAZE
        kaze_keypoints = [r.get('kaze_num_keypoints', 0) for r in self.current_results]
        kaze_density = [r.get('kaze_kp_density', 0) for r in self.current_results]
        
        print(f"\nüîë ESTAD√çSTICAS KAZE:")
        print(f"   Puntos clave promedio: {np.mean(kaze_keypoints):.1f}")
        print(f"   Densidad promedio: {np.mean(kaze_density):.6f}")
        
        # Top im√°genes
        imagenes_hog = [(r['Imagen'], r.get('hog_hog_energy', 0)) for r in self.current_results]
        imagenes_hog.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nüèÜ TOP 3 - MAYOR ENERG√çA HOG:")
        for i, (imagen, energia) in enumerate(imagenes_hog[:3], 1):
            print(f"   {i}. {imagen}: {energia:.2f}")
        
        imagenes_kaze = [(r['Imagen'], r.get('kaze_num_keypoints', 0)) for r in self.current_results]
        imagenes_kaze.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nüéØ TOP 3 - M√ÅS PUNTOS CLAVE KAZE:")
        for i, (imagen, puntos) in enumerate(imagenes_kaze[:3], 1):
            print(f"   {i}. {imagen}: {puntos} puntos")
        
        print("\n" + "=" * 40)
    
    def _guardar_resultados_hog(self, resultados, nombre_imagen):
        """Guarda los resultados HOG en archivos CSV y TXT."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Crear directorio si no existe
        os.makedirs(self.results_dir, exist_ok=True)
        
        # Datos para guardar
        hog_data = {
            'imagen': nombre_imagen,
            'dimensiones': f"{resultados['gray_image'].shape[0]}x{resultados['gray_image'].shape[1]}",
            'num_caracteristicas': resultados['num_features'],
            'valor_min': resultados['hog_min'],
            'valor_max': resultados['hog_max'],
            'promedio': resultados['hog_mean'],
            'desviacion_std': resultados['hog_std'],
            'energia_total': resultados['hog_energy'],
            'entropia': resultados['hog_entropy'],
            'fecha_analisis': datetime.now().isoformat()
        }
        
        # Guardar estad√≠sticas en CSV
        df_stats = pd.DataFrame([hog_data])
        archivo_csv_stats = os.path.join(self.results_dir, f'hog_estadisticas_{nombre_imagen}_{timestamp}.csv')
        df_stats.to_csv(archivo_csv_stats, index=False, encoding='utf-8')
        print(f"‚úÖ Estad√≠sticas HOG guardadas en: {archivo_csv_stats}")
        
        # Guardar caracter√≠sticas completas en CSV
        df_features = pd.DataFrame({
            'indice': range(1, len(resultados['hog_features_raw']) + 1),
            'caracteristica_hog': resultados['hog_features_raw'].flatten()
        })
        archivo_csv_features = os.path.join(self.results_dir, f'hog_caracteristicas_{nombre_imagen}_{timestamp}.csv')
        df_features.to_csv(archivo_csv_features, index=False, encoding='utf-8')
        print(f"‚úÖ Caracter√≠sticas HOG completas guardadas en: {archivo_csv_features}")
        
        # Guardar reporte completo en TXT
        archivo_txt = os.path.join(self.results_dir, f'hog_reporte_completo_{nombre_imagen}_{timestamp}.txt')
        with open(archivo_txt, 'w', encoding='utf-8') as f:
            f.write("REPORTE COMPLETO - AN√ÅLISIS HOG\n")
            f.write("="*60 + "\n\n")
            f.write(f"Imagen analizada: {hog_data['imagen']}\n")
            f.write(f"Fecha de an√°lisis: {hog_data['fecha_analisis']}\n")
            f.write(f"Dimensiones: {hog_data['dimensiones']}\n")
            f.write(f"N√∫mero de caracter√≠sticas: {hog_data['num_caracteristicas']}\n\n")
            
            f.write("ESTAD√çSTICAS GENERALES:\n")
            f.write("-" * 25 + "\n")
            f.write(f"Valor m√≠nimo: {hog_data['valor_min']:.8f}\n")
            f.write(f"Valor m√°ximo: {hog_data['valor_max']:.8f}\n")
            f.write(f"Promedio: {hog_data['promedio']:.8f}\n")
            f.write(f"Desviaci√≥n est√°ndar: {hog_data['desviacion_std']:.8f}\n")
            f.write(f"Energ√≠a total: {hog_data['energia_total']:.8f}\n")
            f.write(f"Entrop√≠a: {hog_data['entropia']:.8f}\n\n")
            
            f.write("CARACTER√çSTICAS HOG COMPLETAS:\n")
            f.write("-" * 35 + "\n")
            for i, feature in enumerate(resultados['hog_features_raw'].flatten(), 1):
                f.write(f"Caracter√≠stica {i:4d}: {feature:18.8f}\n")
        
        print(f"‚úÖ Reporte HOG completo guardado en: {archivo_txt}")
        print(f"üìä Total de archivos generados: 3 (CSV estad√≠sticas, CSV caracter√≠sticas, TXT reporte)")
    
    def _guardar_resultados_kaze(self, resultados, nombre_imagen):
        """Guarda los resultados KAZE en archivos CSV y TXT."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Crear directorio si no existe
        os.makedirs(self.results_dir, exist_ok=True)
        
        # Datos estad√≠sticos generales
        kaze_stats = {
            'imagen': nombre_imagen,
            'dimensiones': f"{resultados['gray_image'].shape[0]}x{resultados['gray_image'].shape[1]}",
            'num_puntos_clave': resultados['num_keypoints'],
            'dimension_descriptor': resultados['descriptor_length'],
            'densidad_puntos': resultados['kp_density'],
            'fecha_analisis': datetime.now().isoformat()
        }
        
        if resultados['descriptors'] is not None:
            kaze_stats.update({
                'valor_min_descriptores': resultados['descriptor_mean'],
                'valor_max_descriptores': resultados['descriptor_std'],
                'promedio_descriptores': resultados['descriptor_energy'],
                'desviacion_std_descriptores': resultados['descriptor_entropy']
            })
        
        # Guardar estad√≠sticas generales en CSV
        df_stats = pd.DataFrame([kaze_stats])
        archivo_csv_stats = os.path.join(self.results_dir, f'kaze_estadisticas_{nombre_imagen}_{timestamp}.csv')
        df_stats.to_csv(archivo_csv_stats, index=False, encoding='utf-8')
        print(f"‚úÖ Estad√≠sticas KAZE guardadas en: {archivo_csv_stats}")
        
        # Guardar informaci√≥n de puntos clave en CSV
        if resultados['keypoints']:
            keypoints_data = []
            for i, kp in enumerate(resultados['keypoints']):
                keypoints_data.append({
                    'punto_clave_id': i + 1,
                    'posicion_x': kp.pt[0],
                    'posicion_y': kp.pt[1],
                    'tama√±o': kp.size,
                    'angulo': kp.angle,
                    'respuesta': kp.response
                })
            
            df_keypoints = pd.DataFrame(keypoints_data)
            archivo_csv_keypoints = os.path.join(self.results_dir, f'kaze_puntos_clave_{nombre_imagen}_{timestamp}.csv')
            df_keypoints.to_csv(archivo_csv_keypoints, index=False, encoding='utf-8')
            print(f"‚úÖ Puntos clave KAZE guardados en: {archivo_csv_keypoints}")
        
        # Guardar descriptores completos en CSV
        if resultados['descriptors'] is not None:
            descriptor_columns = [f'descriptor_{j+1}' for j in range(resultados['descriptors'].shape[1])]
            df_descriptors = pd.DataFrame(resultados['descriptors'], columns=descriptor_columns)
            df_descriptors.insert(0, 'punto_clave_id', range(1, len(resultados['descriptors']) + 1))
            
            archivo_csv_descriptors = os.path.join(self.results_dir, f'kaze_descriptores_{nombre_imagen}_{timestamp}.csv')
            df_descriptors.to_csv(archivo_csv_descriptors, index=False, encoding='utf-8')
            print(f"‚úÖ Descriptores KAZE completos guardados en: {archivo_csv_descriptors}")
        
        # Guardar reporte completo en TXT
        archivo_txt = os.path.join(self.results_dir, f'kaze_reporte_completo_{nombre_imagen}_{timestamp}.txt')
        with open(archivo_txt, 'w', encoding='utf-8') as f:
            f.write("REPORTE COMPLETO - AN√ÅLISIS KAZE\n")
            f.write("="*60 + "\n\n")
            f.write(f"Imagen analizada: {kaze_stats['imagen']}\n")
            f.write(f"Fecha de an√°lisis: {kaze_stats['fecha_analisis']}\n")
            f.write(f"Dimensiones: {kaze_stats['dimensiones']}\n")
            f.write(f"N√∫mero de puntos clave: {kaze_stats['num_puntos_clave']}\n")
            f.write(f"Dimensi√≥n de descriptores: {kaze_stats['dimension_descriptor']}\n\n")
            
            if resultados['descriptors'] is not None:
                f.write("ESTAD√çSTICAS DE DESCRIPTORES:\n")
                f.write("-" * 30 + "\n")
                f.write(f"Promedio: {resultados['descriptor_mean']:.8f}\n")
                f.write(f"Desviaci√≥n est√°ndar: {resultados['descriptor_std']:.8f}\n")
                f.write(f"Energ√≠a: {resultados['descriptor_energy']:.8f}\n")
                f.write(f"Entrop√≠a: {resultados['descriptor_entropy']:.8f}\n\n")
            
            f.write("INFORMACI√ìN DETALLADA DE PUNTOS CLAVE:\n")
            f.write("-" * 45 + "\n")
            for i, kp in enumerate(resultados['keypoints']):
                f.write(f"Punto clave {i+1}:\n")
                f.write(f"  Posici√≥n (x,y): ({kp.pt[0]:.2f}, {kp.pt[1]:.2f})\n")
                f.write(f"  Tama√±o: {kp.size:.2f}\n")
                f.write(f"  √Ångulo: {kp.angle:.2f}¬∞\n")
                f.write(f"  Respuesta: {kp.response:.8f}\n")
                if resultados['descriptors'] is not None:
                    f.write("  Descriptor completo:\n")
                    descriptor_str = ', '.join([f"{val:.8f}" for val in resultados['descriptors'][i]])
                    f.write(f"    [{descriptor_str}]\n")
                f.write("\n")
        
        print(f"‚úÖ Reporte KAZE completo guardado en: {archivo_txt}")
        archivos_generados = 2 + (1 if resultados['keypoints'] else 0) + (1 if resultados['descriptors'] is not None else 0)
        print(f"üìä Total de archivos generados: {archivos_generados}")

# Funci√≥n de utilidad
def analizar_hog_kaze_imagen(imagen_path, output_dir="./resultados"):
    """
    Funci√≥n de conveniencia para an√°lisis HOG-KAZE.
    
    Args:
        imagen_path (str): Ruta a la imagen
        output_dir (str): Directorio de salida
        
    Returns:
        dict: Resultados del an√°lisis
    """
    analyzer = HOGKAZEAnalyzer(output_dir)
    resultado = analyzer.analisis_combinado_hog_kaze(imagen_path)
    if resultado:
        analyzer.guardar_resultados('csv')
        analyzer.generar_reporte_hog_kaze()
    return resultado